{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pdb\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH \n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(input_file, target_file, input_lang, target_lang, size):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    with open(input_file, encoding='utf-8') as file:\n",
    "        input_lines = [next(file).strip() for x in range(size)]\n",
    "        \n",
    "    with open(target_file, encoding='utf-8') as file:\n",
    "        target_lines = [next(file).strip() for x in range(size)]\n",
    "\n",
    "    lines = list(zip(input_lines, target_lines))\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l] for l in lines]\n",
    "    print(pairs[0])\n",
    "\n",
    "    input_lang = Lang(input_lang)\n",
    "    target_lang = Lang(target_lang)\n",
    "\n",
    "    return input_lang, target_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(input_file, target_file, input_lang, target_lang):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    input_lines = open(input_file, encoding='utf-8').read().strip().split(\"\\n\")\n",
    "        \n",
    "    target_lines = open(target_file, encoding='utf-8').read().strip().split(\"\\n\")\n",
    "    if input_lang == \"zh\":\n",
    "        target_pairs = [normalizeString(s) for s in target_lines]\n",
    "        pairs = list(zip(input_lines, target_pairs))\n",
    "    else:\n",
    "        lines = list(zip(input_lines, target_lines))\n",
    "        # Split every line into pairs and normalize\n",
    "        pairs = [[normalizeString(s) for s in l] for l in lines]\n",
    "    print(pairs[0])\n",
    "\n",
    "    input_lang = Lang(input_lang)\n",
    "    target_lang = Lang(target_lang)\n",
    "\n",
    "    return input_lang, target_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "['khoa hoc ang sau mot tieu e ve khi hau', 'rachel pike the science behind a climate headline']\n",
      "Read 50000 sentence pairs\n",
      "Trimmed to 37026 sentence pairs\n",
      "Counting words...\n",
      "['khoa hoc ang sau mot tieu e ve khi hau', 'rachel pike the science behind a climate headline']\n",
      "Counted words:\n",
      "vi 5551\n",
      "eng 19344\n"
     ]
    }
   ],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 30\n",
    "\n",
    "def prepareData(input_file, target_file, input_lang, target_lang, size):\n",
    "    \n",
    "    input_lang, target_lang, pairs = readLangs(input_file, target_file, input_lang, target_lang, size)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    print(pairs[0])\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        target_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(target_lang.name, target_lang.n_words)\n",
    "    return input_lang, target_lang, pairs\n",
    "\n",
    "input_file = 'iwslt-vi-en-processed/train.vi'\n",
    "target_file = 'iwslt-vi-en-processed/train.en'\n",
    "input_lang, target_lang, pairs = prepareData(input_file, target_file, 'vi', 'eng', size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "va tat ca cac trang eu uoc xem xet boi khoa hoc gia va nha phe binh khac tu quoc gia .\n",
      "and all of those pages were reviewed by another plus scientists and reviewers from countries .\n"
     ]
    }
   ],
   "source": [
    "print(pairs[4][0])\n",
    "print(pairs[4][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(pairs, open(\"preprocessed_data_no_elmo/iwslt-vi-eng/preprocessed_no_indices_pairs_test\", \"wb\"))\n",
    "pickle.dump(input_lang, open(\"preprocessed_data_no_elmo/iwslt-zh-eng/preprocessed_no_elmo_zhlang\", \"wb\"))\n",
    "pickle.dump(target_lang, open(\"preprocessed_data_no_elmo/iwslt-zh-eng/preprocessed_no_elmo_englang\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        # output and hidden are the same vectors\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "#### Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    words = sentence.split(' ')\n",
    "    indices = []\n",
    "    for word in words:\n",
    "        if lang.word2index.get(word) is not None:\n",
    "            indices.append(lang.word2index[word])\n",
    "        else:\n",
    "            indices.append(1) # UNK_INDEX\n",
    "    return indices\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair, input_lang, target_lang):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(target_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "# example of input_tensor: [2, 43, 23, 9, 19, 4]. Indexed on our vocabulary. \n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # iterate GRU over words --> final hidden state is representation of source sentence. \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole training process looks like this:\n",
    "\n",
    "-  Start a timer\n",
    "-  Initialize optimizers and criterion\n",
    "-  Create set of training pairs\n",
    "-  Start empty losses array for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cpickle_gc(dirlink):\n",
    "    # https://stackoverflow.com/questions/26860051/how-to-reduce-the-time-taken-to-load-a-pickle-file-in-python\n",
    "    output = open(dirlink, 'rb')\n",
    "\n",
    "    # disable garbage collector\n",
    "    gc.disable()\n",
    "\n",
    "    mydict = pickle.load(output)\n",
    "\n",
    "    # enable garbage collector again\n",
    "    gc.enable()\n",
    "    output.close()\n",
    "    return mydict\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters,n_epochs,  lang1, lang2,  print_every=1000, plot_every=100, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    lang1 is the Lang object for language 1 \n",
    "    Lang2 is the Lang object for language 2\n",
    "    \"\"\"\n",
    "    pairs = load_cpickle_gc(\"preprocessed_data_no_elmo/iwslt-\"+lang1.name+\"-\"+lang2.name+\"/preprocessed_no_indices_pairs_train\")\n",
    "    validation_pairs = load_cpickle_gc(\"preprocessed_data_no_elmo/iwslt-\"+lang1.name+\"-\"+lang2.name+\"/preprocessed_no_indices_pairs_train\")\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    encoder_optimizer = torch.optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = torch.optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    for i in range(n_epochs):\n",
    "        training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                          for i in range(n_iters)]\n",
    "        criterion = nn.NLLLoss()\n",
    "        # framing it as a categorical loss function. \n",
    "        for iter in range(1, n_iters + 1):\n",
    "            training_pair = training_pairs[iter - 1] \n",
    "            d_input_tensor = training_pair[0]\n",
    "            d_target_tensor = training_pair[1]\n",
    "            input_tensor = tensorFromSentence(lang1, d_input_tensor)\n",
    "            target_tensor = tensorFromSentence(lang2, d_target_tensor)\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion, MAX_LENGTH_VI_EN)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('TRAIN SCORE %s (%d %d%%) %.4f' % (timeSince(start, iter / n_epochs),\n",
    "                                             iter, iter / n_epochs * 100, print_loss_avg))\n",
    "                val_loss = test_model(encoder, decoder,search, validation_pairs, lang1, max_length=MAX_LENGTH)\n",
    "                # retursn teh bleu score\n",
    "                print(\"VALIDATION BLEU SCORE: \"+str(val_loss))\n",
    "\n",
    "            if iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 4s (- 30m 30s) (100 0%) 5.5968\n",
      "0m 7s (- 23m 48s) (200 0%) 5.7728\n",
      "0m 9s (- 21m 19s) (300 0%) 5.4151\n",
      "0m 12s (- 19m 50s) (400 1%) 4.8211\n",
      "0m 14s (- 18m 59s) (500 1%) 4.8875\n",
      "0m 16s (- 18m 23s) (600 1%) 5.0768\n",
      "0m 19s (- 17m 55s) (700 1%) 4.8321\n",
      "0m 21s (- 17m 53s) (800 2%) 5.2649\n",
      "0m 24s (- 17m 40s) (900 2%) 5.0137\n",
      "0m 26s (- 17m 28s) (1000 2%) 5.0703\n",
      "0m 29s (- 17m 22s) (1100 2%) 5.2074\n",
      "0m 31s (- 17m 11s) (1200 3%) 5.1661\n",
      "0m 34s (- 17m 4s) (1300 3%) 5.1774\n",
      "0m 36s (- 16m 55s) (1400 3%) 5.0282\n",
      "0m 39s (- 16m 50s) (1500 3%) 4.9627\n",
      "0m 41s (- 16m 44s) (1600 4%) 5.0080\n",
      "0m 44s (- 16m 40s) (1700 4%) 4.9593\n",
      "0m 46s (- 16m 30s) (1800 4%) 4.6759\n",
      "0m 49s (- 16m 24s) (1900 4%) 4.8190\n",
      "0m 51s (- 16m 19s) (2000 5%) 4.8904\n",
      "0m 54s (- 16m 16s) (2100 5%) 4.7480\n",
      "0m 56s (- 16m 12s) (2200 5%) 4.7285\n",
      "0m 59s (- 16m 8s) (2300 5%) 4.7287\n",
      "1m 1s (- 16m 4s) (2400 6%) 5.0598\n",
      "1m 4s (- 16m 0s) (2500 6%) 4.7493\n",
      "1m 6s (- 15m 59s) (2600 6%) 4.9447\n",
      "1m 9s (- 15m 57s) (2700 6%) 5.0564\n",
      "1m 11s (- 15m 54s) (2800 7%) 4.9927\n",
      "1m 14s (- 15m 51s) (2900 7%) 4.9324\n",
      "1m 16s (- 15m 49s) (3000 7%) 4.9841\n",
      "1m 19s (- 15m 46s) (3100 7%) 4.9078\n",
      "1m 22s (- 15m 46s) (3200 8%) 5.1886\n",
      "1m 24s (- 15m 44s) (3300 8%) 4.8566\n",
      "1m 27s (- 15m 41s) (3400 8%) 4.7920\n",
      "1m 30s (- 15m 38s) (3500 8%) 4.8564\n",
      "1m 32s (- 15m 33s) (3600 9%) 4.4394\n",
      "1m 34s (- 15m 29s) (3700 9%) 4.8467\n",
      "1m 37s (- 15m 24s) (3800 9%) 4.8616\n",
      "1m 39s (- 15m 19s) (3900 9%) 4.4001\n",
      "1m 41s (- 15m 17s) (4000 10%) 4.7017\n",
      "1m 44s (- 15m 14s) (4100 10%) 4.9465\n",
      "1m 46s (- 15m 10s) (4200 10%) 4.6156\n",
      "1m 49s (- 15m 7s) (4300 10%) 4.6392\n",
      "1m 51s (- 15m 3s) (4400 11%) 4.8169\n",
      "1m 54s (- 14m 59s) (4500 11%) 4.6897\n",
      "1m 56s (- 14m 55s) (4600 11%) 4.4273\n",
      "1m 58s (- 14m 53s) (4700 11%) 4.6966\n",
      "2m 1s (- 14m 49s) (4800 12%) 4.7226\n",
      "2m 3s (- 14m 46s) (4900 12%) 4.8667\n",
      "2m 6s (- 14m 43s) (5000 12%) 4.8100\n",
      "2m 8s (- 14m 40s) (5100 12%) 4.4022\n",
      "2m 11s (- 14m 37s) (5200 13%) 4.5660\n",
      "2m 13s (- 14m 34s) (5300 13%) 4.6747\n",
      "2m 16s (- 14m 32s) (5400 13%) 4.9193\n",
      "2m 18s (- 14m 29s) (5500 13%) 4.9682\n",
      "2m 20s (- 14m 25s) (5600 14%) 4.7254\n",
      "2m 23s (- 14m 22s) (5700 14%) 4.3678\n",
      "2m 25s (- 14m 19s) (5800 14%) 4.4043\n",
      "2m 28s (- 14m 16s) (5900 14%) 4.6600\n",
      "2m 30s (- 14m 13s) (6000 15%) 4.3333\n",
      "2m 33s (- 14m 10s) (6100 15%) 4.8331\n",
      "2m 35s (- 14m 6s) (6200 15%) 4.4926\n",
      "2m 37s (- 14m 2s) (6300 15%) 4.6145\n",
      "2m 39s (- 13m 59s) (6400 16%) 4.7971\n",
      "2m 42s (- 13m 56s) (6500 16%) 4.6429\n",
      "2m 44s (- 13m 53s) (6600 16%) 4.4878\n",
      "2m 47s (- 13m 50s) (6700 16%) 4.7559\n",
      "2m 49s (- 13m 47s) (6800 17%) 4.5902\n",
      "2m 52s (- 13m 45s) (6900 17%) 4.4723\n",
      "2m 54s (- 13m 41s) (7000 17%) 4.3600\n",
      "2m 56s (- 13m 39s) (7100 17%) 4.4654\n",
      "2m 59s (- 13m 36s) (7200 18%) 4.5938\n",
      "3m 1s (- 13m 34s) (7300 18%) 4.7748\n",
      "3m 4s (- 13m 31s) (7400 18%) 4.6286\n",
      "3m 6s (- 13m 29s) (7500 18%) 5.0247\n",
      "3m 9s (- 13m 26s) (7600 19%) 4.5183\n",
      "3m 11s (- 13m 23s) (7700 19%) 4.8772\n",
      "3m 14s (- 13m 21s) (7800 19%) 4.7525\n",
      "3m 16s (- 13m 18s) (7900 19%) 4.6355\n",
      "3m 19s (- 13m 16s) (8000 20%) 4.6304\n",
      "3m 21s (- 13m 12s) (8100 20%) 4.6308\n",
      "3m 23s (- 13m 9s) (8200 20%) 4.5509\n",
      "3m 26s (- 13m 7s) (8300 20%) 4.5561\n",
      "3m 28s (- 13m 5s) (8400 21%) 4.7568\n",
      "3m 30s (- 13m 1s) (8500 21%) 4.5281\n",
      "3m 33s (- 12m 58s) (8600 21%) 4.6851\n",
      "3m 35s (- 12m 56s) (8700 21%) 4.7312\n",
      "3m 38s (- 12m 53s) (8800 22%) 4.6268\n",
      "3m 41s (- 12m 52s) (8900 22%) 4.8719\n",
      "3m 43s (- 12m 49s) (9000 22%) 4.4930\n",
      "3m 46s (- 12m 47s) (9100 22%) 4.6691\n",
      "3m 48s (- 12m 45s) (9200 23%) 4.5624\n",
      "3m 51s (- 12m 43s) (9300 23%) 4.5920\n",
      "3m 53s (- 12m 40s) (9400 23%) 4.7411\n",
      "3m 56s (- 12m 37s) (9500 23%) 4.7760\n",
      "3m 58s (- 12m 35s) (9600 24%) 4.7115\n",
      "4m 1s (- 12m 33s) (9700 24%) 4.7219\n",
      "4m 3s (- 12m 31s) (9800 24%) 4.8323\n",
      "4m 6s (- 12m 29s) (9900 24%) 4.6119\n",
      "4m 8s (- 12m 26s) (10000 25%) 4.7170\n",
      "4m 11s (- 12m 23s) (10100 25%) 4.3902\n",
      "4m 14s (- 12m 22s) (10200 25%) 4.9247\n",
      "4m 16s (- 12m 20s) (10300 25%) 4.7755\n",
      "4m 19s (- 12m 18s) (10400 26%) 4.9858\n",
      "4m 21s (- 12m 15s) (10500 26%) 4.6654\n",
      "4m 24s (- 12m 13s) (10600 26%) 4.7293\n",
      "4m 26s (- 12m 10s) (10700 26%) 4.6582\n",
      "4m 29s (- 12m 8s) (10800 27%) 4.7076\n",
      "4m 31s (- 12m 6s) (10900 27%) 4.3968\n",
      "4m 34s (- 12m 4s) (11000 27%) 4.7238\n",
      "4m 37s (- 12m 1s) (11100 27%) 4.4605\n",
      "4m 39s (- 11m 59s) (11200 28%) 4.8774\n",
      "4m 42s (- 11m 57s) (11300 28%) 5.1363\n",
      "4m 45s (- 11m 55s) (11400 28%) 4.7445\n",
      "4m 47s (- 11m 52s) (11500 28%) 4.4878\n",
      "4m 49s (- 11m 49s) (11600 28%) 4.5606\n",
      "4m 52s (- 11m 47s) (11700 29%) 4.5934\n",
      "4m 54s (- 11m 44s) (11800 29%) 4.9862\n",
      "4m 57s (- 11m 42s) (11900 29%) 4.5509\n",
      "4m 59s (- 11m 39s) (12000 30%) 4.6794\n",
      "5m 2s (- 11m 37s) (12100 30%) 4.6906\n",
      "5m 5s (- 11m 35s) (12200 30%) 4.7557\n",
      "5m 7s (- 11m 33s) (12300 30%) 4.7760\n",
      "5m 10s (- 11m 31s) (12400 31%) 4.8271\n",
      "5m 13s (- 11m 29s) (12500 31%) 4.8525\n",
      "5m 16s (- 11m 27s) (12600 31%) 4.9036\n",
      "5m 18s (- 11m 24s) (12700 31%) 4.7926\n",
      "5m 21s (- 11m 22s) (12800 32%) 4.8290\n",
      "5m 23s (- 11m 20s) (12900 32%) 4.7433\n",
      "5m 26s (- 11m 17s) (13000 32%) 4.6951\n",
      "5m 28s (- 11m 15s) (13100 32%) 4.6235\n",
      "5m 31s (- 11m 12s) (13200 33%) 4.7423\n",
      "5m 33s (- 11m 10s) (13300 33%) 4.4741\n",
      "5m 36s (- 11m 8s) (13400 33%) 4.6412\n",
      "5m 39s (- 11m 5s) (13500 33%) 4.7424\n",
      "5m 41s (- 11m 2s) (13600 34%) 4.6471\n",
      "5m 44s (- 11m 0s) (13700 34%) 4.6348\n",
      "5m 46s (- 10m 58s) (13800 34%) 4.6611\n",
      "5m 49s (- 10m 56s) (13900 34%) 4.7664\n",
      "5m 51s (- 10m 53s) (14000 35%) 4.7290\n",
      "5m 54s (- 10m 51s) (14100 35%) 4.9311\n",
      "5m 57s (- 10m 48s) (14200 35%) 4.8055\n",
      "5m 59s (- 10m 46s) (14300 35%) 4.4910\n",
      "6m 2s (- 10m 43s) (14400 36%) 4.6303\n",
      "6m 4s (- 10m 41s) (14500 36%) 4.7259\n",
      "6m 7s (- 10m 38s) (14600 36%) 4.7095\n",
      "6m 10s (- 10m 36s) (14700 36%) 4.6971\n",
      "6m 12s (- 10m 34s) (14800 37%) 4.9370\n",
      "6m 15s (- 10m 32s) (14900 37%) 4.9031\n",
      "6m 18s (- 10m 30s) (15000 37%) 4.6724\n",
      "6m 20s (- 10m 27s) (15100 37%) 4.5901\n",
      "6m 23s (- 10m 25s) (15200 38%) 4.7071\n",
      "6m 26s (- 10m 23s) (15300 38%) 4.6044\n",
      "6m 28s (- 10m 21s) (15400 38%) 4.7743\n",
      "6m 31s (- 10m 18s) (15500 38%) 4.7455\n",
      "6m 34s (- 10m 16s) (15600 39%) 4.6470\n",
      "6m 36s (- 10m 13s) (15700 39%) 4.7342\n",
      "6m 39s (- 10m 11s) (15800 39%) 4.5267\n",
      "6m 41s (- 10m 8s) (15900 39%) 4.6176\n",
      "6m 44s (- 10m 6s) (16000 40%) 4.8015\n",
      "6m 46s (- 10m 4s) (16100 40%) 4.7419\n",
      "6m 49s (- 10m 1s) (16200 40%) 4.7470\n",
      "6m 52s (- 9m 59s) (16300 40%) 4.8121\n",
      "6m 54s (- 9m 56s) (16400 41%) 4.6256\n",
      "6m 57s (- 9m 54s) (16500 41%) 4.7228\n",
      "7m 0s (- 9m 52s) (16600 41%) 4.6831\n",
      "7m 2s (- 9m 49s) (16700 41%) 4.5487\n",
      "7m 5s (- 9m 47s) (16800 42%) 4.6291\n",
      "7m 7s (- 9m 44s) (16900 42%) 4.5183\n",
      "7m 10s (- 9m 42s) (17000 42%) 4.5646\n",
      "7m 12s (- 9m 39s) (17100 42%) 4.6639\n",
      "7m 15s (- 9m 37s) (17200 43%) 4.7357\n",
      "7m 18s (- 9m 35s) (17300 43%) 4.8547\n",
      "7m 21s (- 9m 32s) (17400 43%) 4.7828\n",
      "7m 23s (- 9m 30s) (17500 43%) 4.6774\n",
      "7m 26s (- 9m 28s) (17600 44%) 4.5544\n",
      "7m 28s (- 9m 25s) (17700 44%) 4.3512\n",
      "7m 31s (- 9m 23s) (17800 44%) 4.7579\n",
      "7m 34s (- 9m 20s) (17900 44%) 4.7598\n",
      "7m 36s (- 9m 18s) (18000 45%) 4.5131\n",
      "7m 39s (- 9m 16s) (18100 45%) 4.8562\n",
      "7m 42s (- 9m 13s) (18200 45%) 4.5245\n",
      "7m 44s (- 9m 11s) (18300 45%) 4.7439\n",
      "7m 47s (- 9m 8s) (18400 46%) 4.6539\n",
      "7m 50s (- 9m 6s) (18500 46%) 4.4379\n",
      "7m 52s (- 9m 3s) (18600 46%) 4.7838\n",
      "7m 55s (- 9m 1s) (18700 46%) 4.5044\n",
      "7m 57s (- 8m 58s) (18800 47%) 4.6634\n",
      "8m 0s (- 8m 56s) (18900 47%) 4.6093\n",
      "8m 3s (- 8m 54s) (19000 47%) 4.6269\n",
      "8m 5s (- 8m 51s) (19100 47%) 4.6658\n",
      "8m 8s (- 8m 49s) (19200 48%) 4.6261\n",
      "8m 10s (- 8m 46s) (19300 48%) 4.3855\n",
      "8m 13s (- 8m 44s) (19400 48%) 4.4870\n",
      "8m 16s (- 8m 41s) (19500 48%) 4.6586\n",
      "8m 18s (- 8m 39s) (19600 49%) 4.7413\n",
      "8m 21s (- 8m 36s) (19700 49%) 4.4310\n",
      "8m 24s (- 8m 34s) (19800 49%) 4.6311\n",
      "8m 26s (- 8m 31s) (19900 49%) 4.3705\n",
      "8m 29s (- 8m 29s) (20000 50%) 4.4122\n",
      "8m 31s (- 8m 26s) (20100 50%) 4.5789\n",
      "8m 34s (- 8m 24s) (20200 50%) 4.5555\n",
      "8m 37s (- 8m 21s) (20300 50%) 4.6038\n",
      "8m 39s (- 8m 19s) (20400 51%) 4.5222\n",
      "8m 42s (- 8m 16s) (20500 51%) 4.4376\n",
      "8m 45s (- 8m 14s) (20600 51%) 4.7287\n",
      "8m 47s (- 8m 12s) (20700 51%) 4.4713\n",
      "8m 50s (- 8m 9s) (20800 52%) 4.5428\n",
      "8m 53s (- 8m 7s) (20900 52%) 4.3281\n",
      "8m 55s (- 8m 4s) (21000 52%) 4.4413\n",
      "8m 58s (- 8m 2s) (21100 52%) 4.6239\n",
      "9m 0s (- 7m 59s) (21200 53%) 4.5023\n",
      "9m 3s (- 7m 57s) (21300 53%) 4.7512\n",
      "9m 6s (- 7m 54s) (21400 53%) 4.5350\n",
      "9m 9s (- 7m 52s) (21500 53%) 4.7640\n",
      "9m 11s (- 7m 49s) (21600 54%) 4.5546\n",
      "9m 14s (- 7m 47s) (21700 54%) 4.7179\n",
      "9m 16s (- 7m 44s) (21800 54%) 4.5494\n",
      "9m 19s (- 7m 42s) (21900 54%) 4.6691\n",
      "9m 22s (- 7m 39s) (22000 55%) 4.6252\n",
      "9m 25s (- 7m 37s) (22100 55%) 4.4207\n",
      "9m 27s (- 7m 35s) (22200 55%) 4.5003\n",
      "9m 30s (- 7m 32s) (22300 55%) 4.4855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9m 33s (- 7m 30s) (22400 56%) 4.6210\n",
      "9m 35s (- 7m 27s) (22500 56%) 4.3865\n",
      "9m 38s (- 7m 25s) (22600 56%) 4.5847\n",
      "9m 41s (- 7m 22s) (22700 56%) 4.7381\n",
      "9m 43s (- 7m 20s) (22800 56%) 4.4532\n",
      "9m 46s (- 7m 17s) (22900 57%) 4.5935\n",
      "9m 49s (- 7m 15s) (23000 57%) 4.6728\n",
      "9m 51s (- 7m 12s) (23100 57%) 4.5673\n",
      "9m 54s (- 7m 10s) (23200 57%) 4.3248\n",
      "9m 57s (- 7m 7s) (23300 58%) 4.3180\n",
      "9m 59s (- 7m 5s) (23400 58%) 4.6260\n",
      "10m 2s (- 7m 3s) (23500 58%) 4.6635\n",
      "10m 5s (- 7m 0s) (23600 59%) 4.4617\n",
      "10m 7s (- 6m 57s) (23700 59%) 4.5282\n",
      "10m 10s (- 6m 55s) (23800 59%) 4.6344\n",
      "10m 12s (- 6m 52s) (23900 59%) 4.3259\n",
      "10m 15s (- 6m 50s) (24000 60%) 4.3940\n",
      "10m 17s (- 6m 47s) (24100 60%) 4.3862\n",
      "10m 20s (- 6m 45s) (24200 60%) 4.3457\n",
      "10m 23s (- 6m 42s) (24300 60%) 4.5836\n",
      "10m 26s (- 6m 40s) (24400 61%) 4.6074\n",
      "10m 28s (- 6m 37s) (24500 61%) 4.6000\n",
      "10m 31s (- 6m 35s) (24600 61%) 4.7515\n",
      "10m 34s (- 6m 32s) (24700 61%) 4.3044\n",
      "10m 36s (- 6m 30s) (24800 62%) 4.5589\n",
      "10m 39s (- 6m 27s) (24900 62%) 4.6115\n",
      "10m 42s (- 6m 25s) (25000 62%) 4.4643\n",
      "10m 45s (- 6m 23s) (25100 62%) 4.5307\n",
      "10m 48s (- 6m 20s) (25200 63%) 4.4473\n",
      "10m 50s (- 6m 18s) (25300 63%) 4.4768\n",
      "10m 53s (- 6m 15s) (25400 63%) 4.3155\n",
      "10m 55s (- 6m 12s) (25500 63%) 4.4728\n",
      "10m 58s (- 6m 10s) (25600 64%) 4.6129\n",
      "11m 1s (- 6m 8s) (25700 64%) 4.4706\n",
      "11m 4s (- 6m 5s) (25800 64%) 4.7007\n",
      "11m 6s (- 6m 3s) (25900 64%) 4.5354\n",
      "11m 9s (- 6m 0s) (26000 65%) 4.5832\n",
      "11m 12s (- 5m 58s) (26100 65%) 4.6370\n",
      "11m 14s (- 5m 55s) (26200 65%) 4.4925\n",
      "11m 17s (- 5m 53s) (26300 65%) 4.4449\n",
      "11m 20s (- 5m 50s) (26400 66%) 4.4314\n",
      "11m 23s (- 5m 48s) (26500 66%) 4.3198\n",
      "11m 25s (- 5m 45s) (26600 66%) 4.3777\n",
      "11m 28s (- 5m 42s) (26700 66%) 4.3640\n",
      "11m 31s (- 5m 40s) (26800 67%) 4.4302\n",
      "11m 33s (- 5m 37s) (26900 67%) 4.5432\n",
      "11m 36s (- 5m 35s) (27000 67%) 4.5765\n",
      "11m 39s (- 5m 32s) (27100 67%) 4.3986\n",
      "11m 41s (- 5m 30s) (27200 68%) 4.3889\n",
      "11m 44s (- 5m 27s) (27300 68%) 4.6062\n",
      "11m 47s (- 5m 25s) (27400 68%) 4.4148\n",
      "11m 49s (- 5m 22s) (27500 68%) 4.7000\n",
      "11m 52s (- 5m 20s) (27600 69%) 4.4609\n",
      "11m 55s (- 5m 17s) (27700 69%) 4.5390\n",
      "11m 57s (- 5m 15s) (27800 69%) 4.1722\n",
      "12m 0s (- 5m 12s) (27900 69%) 4.6828\n",
      "12m 3s (- 5m 9s) (28000 70%) 4.6103\n",
      "12m 5s (- 5m 7s) (28100 70%) 4.6022\n",
      "12m 8s (- 5m 4s) (28200 70%) 4.4914\n",
      "12m 10s (- 5m 2s) (28300 70%) 4.3267\n",
      "12m 13s (- 4m 59s) (28400 71%) 4.6309\n",
      "12m 16s (- 4m 57s) (28500 71%) 4.3318\n",
      "12m 18s (- 4m 54s) (28600 71%) 4.4079\n",
      "12m 21s (- 4m 51s) (28700 71%) 4.5046\n",
      "12m 24s (- 4m 49s) (28800 72%) 4.3540\n",
      "12m 26s (- 4m 46s) (28900 72%) 4.5727\n",
      "12m 29s (- 4m 44s) (29000 72%) 4.5825\n",
      "12m 32s (- 4m 41s) (29100 72%) 4.3685\n",
      "12m 34s (- 4m 39s) (29200 73%) 4.4584\n",
      "12m 37s (- 4m 36s) (29300 73%) 4.5813\n",
      "12m 39s (- 4m 33s) (29400 73%) 4.4948\n",
      "12m 42s (- 4m 31s) (29500 73%) 4.4763\n",
      "12m 45s (- 4m 28s) (29600 74%) 4.3541\n",
      "12m 47s (- 4m 26s) (29700 74%) 4.7247\n",
      "12m 50s (- 4m 23s) (29800 74%) 4.5787\n",
      "12m 53s (- 4m 21s) (29900 74%) 4.5509\n",
      "12m 55s (- 4m 18s) (30000 75%) 4.2950\n",
      "12m 58s (- 4m 16s) (30100 75%) 4.5020\n",
      "13m 1s (- 4m 13s) (30200 75%) 4.4540\n",
      "13m 3s (- 4m 10s) (30300 75%) 4.4023\n",
      "13m 6s (- 4m 8s) (30400 76%) 4.4119\n",
      "13m 8s (- 4m 5s) (30500 76%) 4.5245\n",
      "13m 11s (- 4m 3s) (30600 76%) 4.4063\n",
      "13m 14s (- 4m 0s) (30700 76%) 4.3551\n",
      "13m 17s (- 3m 58s) (30800 77%) 4.5047\n",
      "13m 19s (- 3m 55s) (30900 77%) 4.4799\n",
      "13m 22s (- 3m 53s) (31000 77%) 4.3508\n",
      "13m 25s (- 3m 50s) (31100 77%) 4.4596\n",
      "13m 28s (- 3m 47s) (31200 78%) 4.6066\n",
      "13m 30s (- 3m 45s) (31300 78%) 4.3336\n",
      "13m 33s (- 3m 42s) (31400 78%) 4.6051\n",
      "13m 36s (- 3m 40s) (31500 78%) 4.4969\n",
      "13m 38s (- 3m 37s) (31600 79%) 4.4899\n",
      "13m 41s (- 3m 35s) (31700 79%) 4.4163\n",
      "13m 44s (- 3m 32s) (31800 79%) 4.6293\n",
      "13m 46s (- 3m 29s) (31900 79%) 4.2859\n",
      "13m 49s (- 3m 27s) (32000 80%) 4.1133\n",
      "13m 51s (- 3m 24s) (32100 80%) 4.4451\n",
      "13m 54s (- 3m 22s) (32200 80%) 4.6406\n",
      "13m 57s (- 3m 19s) (32300 80%) 4.4005\n",
      "13m 59s (- 3m 16s) (32400 81%) 4.4453\n",
      "14m 2s (- 3m 14s) (32500 81%) 4.4686\n",
      "14m 4s (- 3m 11s) (32600 81%) 4.5295\n",
      "14m 7s (- 3m 9s) (32700 81%) 4.6113\n",
      "14m 10s (- 3m 6s) (32800 82%) 4.4029\n",
      "14m 12s (- 3m 4s) (32900 82%) 4.2065\n",
      "14m 15s (- 3m 1s) (33000 82%) 4.4589\n",
      "14m 17s (- 2m 58s) (33100 82%) 4.3894\n",
      "14m 20s (- 2m 56s) (33200 83%) 4.5074\n",
      "14m 23s (- 2m 53s) (33300 83%) 4.4352\n",
      "14m 26s (- 2m 51s) (33400 83%) 4.3446\n",
      "14m 28s (- 2m 48s) (33500 83%) 4.3199\n",
      "14m 31s (- 2m 46s) (33600 84%) 4.4160\n",
      "14m 34s (- 2m 43s) (33700 84%) 4.3904\n",
      "14m 36s (- 2m 40s) (33800 84%) 4.2603\n",
      "14m 39s (- 2m 38s) (33900 84%) 4.3630\n",
      "14m 42s (- 2m 35s) (34000 85%) 4.5154\n",
      "14m 44s (- 2m 33s) (34100 85%) 4.5173\n",
      "14m 47s (- 2m 30s) (34200 85%) 4.3590\n",
      "14m 50s (- 2m 27s) (34300 85%) 4.1152\n",
      "14m 52s (- 2m 25s) (34400 86%) 4.2679\n",
      "14m 55s (- 2m 22s) (34500 86%) 4.3948\n",
      "14m 58s (- 2m 20s) (34600 86%) 4.6218\n",
      "15m 0s (- 2m 17s) (34700 86%) 4.2999\n",
      "15m 3s (- 2m 14s) (34800 87%) 4.4457\n",
      "15m 6s (- 2m 12s) (34900 87%) 4.4196\n",
      "15m 8s (- 2m 9s) (35000 87%) 4.4134\n",
      "15m 11s (- 2m 7s) (35100 87%) 4.2378\n",
      "15m 13s (- 2m 4s) (35200 88%) 4.6476\n",
      "15m 16s (- 2m 2s) (35300 88%) 4.5723\n",
      "15m 19s (- 1m 59s) (35400 88%) 4.3656\n",
      "15m 21s (- 1m 56s) (35500 88%) 4.4158\n",
      "15m 24s (- 1m 54s) (35600 89%) 4.3560\n",
      "15m 27s (- 1m 51s) (35700 89%) 4.3122\n",
      "15m 29s (- 1m 49s) (35800 89%) 4.5110\n",
      "15m 32s (- 1m 46s) (35900 89%) 4.3655\n",
      "15m 34s (- 1m 43s) (36000 90%) 4.4143\n",
      "15m 37s (- 1m 41s) (36100 90%) 4.2510\n",
      "15m 40s (- 1m 38s) (36200 90%) 4.2845\n",
      "15m 43s (- 1m 36s) (36300 90%) 4.4034\n",
      "15m 45s (- 1m 33s) (36400 91%) 4.5232\n",
      "15m 48s (- 1m 30s) (36500 91%) 4.4718\n",
      "15m 50s (- 1m 28s) (36600 91%) 4.3420\n",
      "15m 53s (- 1m 25s) (36700 91%) 4.5627\n",
      "15m 56s (- 1m 23s) (36800 92%) 4.3819\n",
      "15m 58s (- 1m 20s) (36900 92%) 4.3136\n",
      "16m 1s (- 1m 17s) (37000 92%) 4.3240\n",
      "16m 3s (- 1m 15s) (37100 92%) 4.4782\n",
      "16m 6s (- 1m 12s) (37200 93%) 4.3534\n",
      "16m 9s (- 1m 10s) (37300 93%) 3.9976\n",
      "16m 11s (- 1m 7s) (37400 93%) 4.3025\n",
      "16m 14s (- 1m 4s) (37500 93%) 4.4960\n",
      "16m 17s (- 1m 2s) (37600 94%) 4.3693\n",
      "16m 19s (- 0m 59s) (37700 94%) 4.2993\n",
      "16m 22s (- 0m 57s) (37800 94%) 4.2720\n",
      "16m 25s (- 0m 54s) (37900 94%) 4.3368\n",
      "16m 27s (- 0m 51s) (38000 95%) 4.2907\n",
      "16m 30s (- 0m 49s) (38100 95%) 4.4847\n",
      "16m 33s (- 0m 46s) (38200 95%) 4.7161\n",
      "16m 35s (- 0m 44s) (38300 95%) 4.3586\n",
      "16m 38s (- 0m 41s) (38400 96%) 4.1788\n",
      "16m 41s (- 0m 39s) (38500 96%) 4.2316\n",
      "16m 44s (- 0m 36s) (38600 96%) 4.3210\n",
      "16m 47s (- 0m 33s) (38700 96%) 4.4269\n",
      "16m 49s (- 0m 31s) (38800 97%) 4.2541\n",
      "16m 52s (- 0m 28s) (38900 97%) 3.9754\n",
      "16m 54s (- 0m 26s) (39000 97%) 4.2390\n",
      "16m 57s (- 0m 23s) (39100 97%) 4.0835\n",
      "16m 59s (- 0m 20s) (39200 98%) 4.6319\n",
      "17m 2s (- 0m 18s) (39300 98%) 4.0464\n",
      "17m 5s (- 0m 15s) (39400 98%) 4.3797\n",
      "17m 7s (- 0m 13s) (39500 98%) 4.4234\n",
      "17m 10s (- 0m 10s) (39600 99%) 4.3242\n",
      "17m 13s (- 0m 7s) (39700 99%) 4.5336\n",
      "17m 15s (- 0m 5s) (39800 99%) 4.3476\n",
      "17m 18s (- 0m 2s) (39900 99%) 4.2742\n",
      "17m 20s (- 0m 0s) (40000 100%) 4.3643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f37684b6358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJztnXeYHMWZxt+ve9JGpV0FJIFQIJnstQyIIIJNNNhnzofP+WzL2PjA5wSYcz5sHI9zOGOBM8Y4YnPkKGMwwRIgBEggoYCEwq60OUyu+6O7uqtrqifszoZZfb/n0aOZ6Z7ump7Zt75+66uvSAgBhmEYZnJhjXcDGIZhmOrD4s4wDDMJYXFnGIaZhLC4MwzDTEJY3BmGYSYhLO4MwzCTEBZ3hmGYSQiLO8MwzCSExZ1hGGYSEhmvE7e0tIgFCxaM1+kZhmFqkjVr1uwVQrSW2m/cxH3BggVYvXr1eJ2eYRimJiGibeXsx7YMwzDMJITFnWEYZhJSli1DRFsB9AHIAcgKIdq07VMA3AzgQPeY3xZC/Ky6TWUYhmHKpRLP/XQhxN6QbZcBeFEI8RYiagXwEhH9WgiRHnkTGYZhmEqpli0jADQREQFoBNAJIFulYzMMwzAVUq64CwD3EdEaIlph2P4DAIcD2AlgHYArhBB5fSciWkFEq4lodUdHx7AbzTAMwxSnXHFfJoQ4HsC5AC4jolO17WcDeBbAAQCOBfADImrWDyKEWCmEaBNCtLW2lkzTZBiGYYZJWeIuhNjp/t8O4DYAS7VdPgDgT8JhE4AtAA6rZkNVtncO4q8vc+TPMAwTRklxJ6IGImqSjwG8GcDz2m6vAjjT3WcWgEMBbK5uU31O+9bDeN9PnxqtwzMMw9Q85WTLzAJwmzNWigiAW4QQ9xDRpQAghLgBwFcB/JyI1gEgAFcWyawZMXle05thGKYoJcVdCLEZwDGG129QHu+EE9EzDMMwEwCeocowDDMJqWlxz7E/wzAMY6SmxT2TK0ilZxiGYVDj4p7lyJ1hGMZIbYs7R+4MwzBGalrcMzmO3BmGYUzUtLhn8xy5MwzDmKhtcefInWEYxkjNibuaIcPZMgzDMGZqTtyTmZz3mLNlGIZhzNScuA8p4s6RO8MwjJmaE/dk2hd09twZhmHM1Jy4DwVsGY7cGYZhTJS1QDYRbQXQByAHICuEaDPssxzA9QCiAPYKIU6rXjN9grYMR+4MwzAmyhJ3l9PDarQT0VQA/wvgHCHEq0Q0syqtMzCUViJ3FneGYRgj1bJl/hXOMnuvAt5yfKOCmi2TYVuGYRjGSLniLgDcR0RriGiFYfshAKYR0Sp3n/eaDkJEK4hoNRGt7ugY3hqoAc+dI3eGYRgj5Yr7MiHE8QDOBXAZEZ2qbY8AeD2A8wGcDeDzRHSIfhAhxEohRJsQoq21tXVYDT5m/lR8dPkiAFw4jGEYJoyyxN1dRk/aLbcBWKrtsgPAPUKIAdeXfwSGpfmqwdypdXj78XMBABmexMQwDGOkpLgTUQMRNcnHcNZKfV7b7S8ATiGiCBHVA3gjgPXVbqwkYjnN5sidYRjGTDnZMrMA3EZEcv9bhBD3ENGlgLNQthBiPRHdA+A5AHkANwkh9A6geo22CQB77gzDMGGUFHchxGYYLBYhxA3a828B+Fb1mhZO1HYid86WYRiGMVNzM1QBIGJx5M4wDFOM2hR3Gbmz584wDGOkJsU9Kj13zpZhGIYxUpPiztkyDMMwxalJcZeROxcOYxiGMVOT4k5EsC3ikr8MwzAh1KS4A07GDGfLMAzDmKlZcY/aFtsyDMMwIdSsuEdstmUYhmHCqF1xtzhyZxiGCaNmxT1qE6dCMgzDhFCz4u7YMhy5MwzDmKhZcY9aFpcfYBiGCaEscSeirUS0joieJaLVRfZ7AxHliOji6jXRTMTmVEiGYZgwyqnnLjndXWXJCBHZAL4B4N4Rt6oMIpbF2TIMwzAhVNOW+XcAfwTQXsVjhmJbhBx77gzDMEbKFXcB4D4iWkNEK/SNRDQXwNsA3FDwzuB+K4hoNRGt7ujoqLy1CpZFYFeGYRjGTLnivkwIcTyAcwFcRkSnatuvB3ClECJX7CBCiJVCiDYhRFtra+swmutjE5DnyJ1hGMZIWZ67EGKn+387Ed0GYCmAR5Rd2gDc6q6z2gLgPCLKCiH+XOX2erAtwzAME05JcSeiBgCWEKLPffxmAF9R9xFCHKzs/3MAd4ymsAOARYScYHFnGIYxUU7kPgvAbW5UHgFwixDiHiK6FChcKHussC1COsvZMgzDMCZKirsQYjOAYwyvG0VdCPH+kTerNLbFkTvDMEwYNTtD1SLiAVWGYZgQalbcOXJnGIYJp2bF3SICl5ZhGIYxU7Pibluc584wDBNGDYs72zIMwzBh1Ky484AqwzBMODUr7hy5MwzDhFO74k5cfoBhGCaMmhV30myZnz66BRv39I1jixiGYSYONSvutgXPlhFC4Ct3vIgLvv/oOLeKYRhmYlDD4u7nuUt7JsW1ZhiGYQDUsLhbRBBu5J5l751hGCZAzYq7mi3D4s4wDBOkrMU6iGgrgD4AOQBZIUSbtv1dAK50n/YD+KgQYm0V21mApWTL5Hi9PYZhmABlibvL6UKIvSHbtgA4TQjRRUTnAlgJ4I0jbl0RbMvPlsnmfa+9vS+JbE7ggKl1o3l6hmGYCU0l4h6KEOLvytMnAMyrxnGLodoyar77suseQiYnsPW680e7CQzDMBOWcj13AeA+IlpDRCtK7PtBAHebNhDRCiJaTUSrOzo6KmlnAU75Aeex6rlnXIsmO8ySkb3JDDoH0iNqG8MwzHhTrrgvE0IcD+BcAJcR0ammnYjodDjifqVpuxBipRCiTQjR1traOqwGS9Q8d9NM1W2dg8M67glfexDHf/X+EbWNYRhmvClL3IUQO93/2wHcBmCpvg8RHQ3gJgAXCSH2VbORJtTyA6ZsmTO/81c8t6O74uMOpnMjbhvDMMx4U1LciaiBiJrkYwBvBvC8ts+BAP4E4D1CiJdHo6E6lkUAnJruOWVAtT5me4+ff613LJrCMAwz4ShnQHUWgNuISO5/ixDiHiK6FPAWyv4CgBkA/tfdryBdstrYznmQEyIQuasWjQCnSDIMs39SUtyFEJsBHGN4/Qbl8YcAfKi6TSuOjNxzeYGskueeyuax4tSFWPnIZgym2GJhGGb/pKZnqAJAXovcAaC1MQ4AGEhnx7xdtcqjG/diy96B8W4GwzBVoip57uOBZ8tonjsANCUiqIvaPDhaAe/+yZMAwPMDGGaSULORuz+gioAtAwAN8Qga4jYGUhy5Mwyzf1Kz4m472o6cEAV57o3xCOpiHLkzDLP/Urvirg6o5g2ReyyCwRF47oLXZ2UYpoapWXG3lAFVPXJviNuoH2HkntmPKk3yWrQMM/moWXFXB1T1yL0xHkFDPDIizz0zzNo0tUiaV7BimElHzWbLyMj9p49uwU2Pbglsa4hHUB+z0dGXGvbx9UHayQyLO8NMPmo+cteFHXAj91ik4jx31Z7I5PcfwUvleOCZYSYbtSvubuRuIhG1UR+3i85Qff1X78c51z+C51/rwXfuewlA0IphW4ZhmFqmZsXdChH3xrjjNNWXiNz3DaSxYXcf7nhuF77/0Cb0JjNIK4LOtgzDMLVMzYq7tGV0ZjY5pQfqYzaSmXzJTJDeZAYAsLsniUx2P43c96PPyjD7C7Ur7iEtb3HFvSHmRPClct17hxxx39k9FEh/HM9UyM6BNIbGcAIWR+4MM/koS9yJaCsRrSOiZ4lotWE7EdH3iGgTET1HRMdXv6lBrJDIvdUV9yl1UQBA92Cm6HF6k4747+pJThjP/fiv3o8Lf/DomJ1vf7pLYZj9hUoi99OFEMeG1Gk/F8AS998KAD+qRuOKETagesScZgDArCkJAMBDG9qxpzcZepw+15bZ1ZNESolgTas7jSUb2/vH7FwpjtwZZtJRLVvmIgC/FA5PAJhKRHOqdGwjpgHVa992JD5y6kIAwOxmR9y/ePsLOOf6R0KPI22ZXd1DEyZyH2vYlmGYyUe54i4A3EdEa4hohWH7XADblec73NcCENEKIlpNRKs7Ojoqb62CaUD17cfPQ8Q146W4A0BXEWtmItoyYw2LO8NMPsoV92VCiOPh2C+XEdGp2naTR1LgawghVgoh2oQQba2trRU2NYjJllFfa64rb/KtjNw3tvfhozc/7b0+GWvLfORXq3H5b54peF3PlulPZbHgqjvx52deG6umMQxTZcoSdyHETvf/dgC3AViq7bIDwHzl+TwAO6vRwDBMA6pqNE/a9p6Q6D2VzYMI2NObwmvdQ97r2UkYud/7wh7cvrbwa9Ej99e6nOvww4c3jUm7GIapPiXFnYgaiKhJPgbwZgDPa7vdDuC9btbMCQB6hBC7qt5aBVPkHjaxCQC27vOXkNPL+c6fVl+w/0gi9909SSy46k789eWRWU9jBdsyDDP5KCdynwXgUSJaC+ApAHcKIe4hokuJ6FJ3n7sAbAawCcCNAD42Kq1VCMtzVznr8Jne422dg95jfWLTobObCt47Es/9kY2OqN/29I6K35sfhyydsElMIdmmDMPUACWNaSHEZgDHGF6/QXksAFxW3aYVJyzPXeWm970BO7uHcNJ1D2FQKf+rR+WHzW7C/S/uCbyWNRQOu+f5XZhaH8MJC2cUPe+ubif18oCpdSXbqDMeBcv0yF0UDpcwDFNj1PAM1fLCyljE+YiBTBhNQBfPbCx4n8mWufTmp3HJyidKnnOn691Pb4iV1UaV8Vg4IzRyN46Tj4xsLo8frXqF17dlmFGmZsW9nMgdAKKuf5NWxFovCnbQjIaC943EltnlTpoaTs2W0Zo8taNrMHSbGrkLw8pWw+WXj2/F6d9eFXjtbxv34hv3bMCX/++FqpyDYRgzNSvu5UbucTdyTxcpCtYYt/GHS08MvDaSqpC73Mh9OAOVo1GN8i/PvoaTv/Fw6Ha1nbm8L+4j9dy/8JcXsGXvQGAcoS5mAwBWb+0a2cEZhinKpBd3GbkXm6AUj9hoWzAdiagVuk8l7BtIAximuI+C5/78az1Ft6e1sgvVzvFXSy/L67p570DY7gzDVIGaFfdybRnbIliki3tQvBJRJ5pcccrC0H0qQYrlRInc5ecLI1DHPh9uywgh8JbvP4q/PFvZ5KZ+xV9PZfxzcQomw4weNSvu5UbugDOoms7l8ez2bmzZO1AwQUlG7P/xpkPw4lfOBjCySUxStIZTkGs0BlSlNRVGwJbJidDP3jmQxrrXenDFrc9WdP7+pC/uakcii7YxDFN9anaB7LDFOkxEbQvpbB5v/eFjAIC7Lj8lsF1GtkSEOvdxRhPZcvPP83nhCdhwItPRqGlTMnJXxyPyeW9QV5/l+6o7V2BqfbSs89oWIZcXXv0e/VxcjZJhRo+ajdytCloec8VdogtoVJkRRUSI2lSwT7mZL+p+w8mWUSP3U775EHqGwqNbIQQeeHFPyWi/ZOSutDOXF6G+vxT3afXlpXhG3LurgC2TzSmPWdwZZrSoWXGvxJaJ2ha6BtPe81KDlhHLClgTm9r7iuZl//ivr+Drd60HEBRKVcjKRfX6t3cOFU1hvPeFPfjQL1dj5SObix4zHglG7npnkA2sQJUP9f237XPa0lxXXuQeczvN/tDIfexWm2KY/Y3aFfcKbJlYxPKKYQGlB0sjNmFzxwC+dPsL+NvGDpz13Ufwi8e3he7/9bs34MeuwKriNRxbRhdeVRh1dvc4n2lXz1DoPib0uxI1t96J3IuLe7mfK2LLyN2/+0iN8PqoCCFw61Oveuvgqq9/9/6X8fKevhEdn2FqmZr13IsVCdOJ2oQdAXEvLirNiSge3NAOAF5mSG8Re0SSz4uAeA3HdtBnz/YVEXepwaUyh3JaobRMLh/w4dU7mUxOeNdHP+rGdkcsy7kWgG93qZ9hpNdHZd1rPbjqT+vw6Ka9+MG/+is7prJ5fO/BjYhYhENmFdYNYpj9gf0ico/alpd7DpRON5w9pXChj3JO196XCh0wzObyZS16rUfufalwIc27ol1K3PVIXL9zUc+ZzeeNHn73oJMpA6AgUg5Deu59YbZMZmTiLj+HvKPwzuF2TpOxbDPDlEvNinslkXtMG1AsNdCpruIkGUyVFuYdXYOhtsylNz+Nw79wT8lj6HcVxWwZX9wLt93z/C4suOpO7OgaLMj00UUvq5VmkM/VPuOxTfsgBHDKkhb0JbP42l3rC0on68jrHBxQVQecR+a5y84ymQkeR7Zfz3himP2JssWdiGwieoaI7jBsO5CIHna3P0dE51W3mYVIQWtpjOO+/zgV9/+HvjiUT0yrD1zKDlAjd8mgIiDdg2njrM/XuodCxf2B9XsK9jehR829RcRdarRpcPnWfzirHr68p6/gmHrnFozczZ77M692IR6xcPLiFgDAykc2Y29/umA/laQbmYcOqI4wcpd58kMF4s6RO8NU4rlfAWA9gGbDtv8E8DshxI+I6Ag49d0XjLx54TQlovjM2Yfi/KPmYEFLYeEvlagm7j2DxUXJFLkPKVPo33njk1i/qxdbvh7sw3Z0DWGuW+a3KREZXuEwzTIp7rm7kbtB3KVwxiN20ewYIOjz5/J5z4NXI/dtnYM4cHo9pimVLrsH02htioe2T2bDjCQV8r/vfxnxqIWPLV9csK3PPa4eucuIfTIulcgw5VJW5E5E8wCcD+CmkF0EfNGfglFeYk9y2emLSwo7AEQ1W6a7yILZQEjkrvjl63f1AnDEKalEn50DaS8ybU5Ejal+Qgjs7U+FnluPmvuLee75cFtGntsiMg6oquTywsuFzyi2jMr2zkEcNKMezQk/HlDHMXRySo2avpQ5cg/LlhFC4L/vfxmvdPTjfx7ciG/e85JxP9nx6WMZMmLfnxY5Zxidcm2Z6wF8FkDYX8uXALybiHbAidr/3bQTEa0gotVEtLqjY+yWoIvZQfXrLpHtYRL3AcNgaH8qGyiKlcsLpFxBaYxHjOL17PZuvOHaB7Cpvd94bt1KKCdbxjS4LKPidK5wgFSPaLM54WXPqJOYZD13IQRe7RzEgdMbAp1cZxFxV6PptNLJpXN5NLiVIcPy3HuGMvifBzeWrJ2v2jLquELGs2U4cmf2X8pZQ/UCAO1CiDVFdnsngJ8LIeYBOA/Ar4io4NhCiJVCiDYhRFtra+uwG10p+oBqqcj98DmFzpNqy0j6k9nA5KZsPu8JelPCLO6vdg5CiPDcdD1yLybuMiLXywQAvrgnMzmDuBeL3PMFbdjbn8ZgOocDp9fhzMNn4dj5UwEUj9xVcVdFNpXJe5OgwmwZ+XpHX/gdDuBfm7wIdtiy85KfczCdxWd+vxZdRdrLMJONciL3ZQAuJKKtAG4FcAYR3azt80EAvwMAIcTjABIAWqrYzhEhPXdpKRSb0g84UfctH3pj4DV90A5wI3cliyan5Lk3JSJG8ZIDpAOG7JvNHf343J/WBc9RLHL3bBlf3H/1+FZ8/s/Pe1FxKlsYueszdDP5fDBy17Jl5OLiB81owJS6KH73Eaf2fTGxTIaUe0jn8mhyvwd5fR7btBc/e2yL/17DtTahFh7bp1hderbM71fvwO/X7MD1D7xc1nEZZjJQUtyFEFcLIeYJIRYAuATAQ0KId2u7vQrgTAAgosPhiPvY+S4lkOI+0x0o7RnyRSkSklIZ0QZhTTnqfcksBgO1yoUXrTcmosbIXYr1UKZQtD9+yzMBfxoonlMuI/e84ql//i8v4FdPbPMGVFOZnLddLhiezhbmucvKmJmcny0jD/vQhnbYFuEYN2KPRSw0JSKhtkw2l8eHf7Hae66ugpXO5tEYD4r7u256El/+vxc9UTd1pCbUuxp5nZwONue1Q2U0MiNvefLVQMfCMBOFYee5E9FXiOhC9+mnAHyYiNYC+A2A94tSSdBjiCfubmaHasuE5cvr6YWmSHsglQ1kguTyImDLmGqjy2hzMJ3DjY9sxobdvd62vOGSqQImhMCXbn8Ba7d3AwAy7rlkJK6eS9bSSWUdmyVqEy49bZHzPkOeezBy948nhMAdz+3EssUtgTVhZzTEQm2Z9r4UXnQHnS0Kimwqm0M8YiMWsTwRlh3ss+7nKmeyl7w28mvqGcpg454+HPKfd+PiGx4PfE55B1LNhb+zuTxe2NmDz922ruISyOWSz4uSd5kME0ZF4i6EWCWEuMB9/AUhxO3u4xeFEMuEEMcIIY4VQtw3Go0dLtJPlml7XYq4z3NTF3X0iD7MllEHGLN54Q0eSutBj977PFsmi2vvWo/zv/eot82Ur652HgPpHH7+9634l5WOeKW1gcNXOvxBWuk7p7J55PMCFpF3N6LbMqrnrs5QzeUFOgfS2N45hFOXBF22aQ0xdA2kIYQvQPK52iE1xiNBWyabRyxiIR6xvLuLIw5wxjie2tIJAIEMJIkpVuhLZjBvWj0AV9zb+wMdXPdgBi/u7PXGJKoZuf/rTU96312psYHh8vW71+OYL98X+A0wTLnU7AzVSpCe9EHT6zGjIYa9/SlELML1/3IsbvnwCcb3lFN1si/lD6jWRW1kc3nfc4+HibsjhL1DzvtUMQoTdyls8ljy80hxlDbKizt7C96fyjoDqrbllDJ2jlPowcvIPZ3N+wOS+Tx2u4t9z9U6wZbGONr7kvjBQ5twzJfvw3M7unHcV+/HjX/bHIg2mxLRQHZOKptH3BV32TnJSWYv7e7DpvY+o+dumjPQl8xi3jSnXT2DmYKB4NXbunDe9/7mjU2E3Ut+6ndrseCqO80bQ5AdEVD6juCGv76C1Vs7i+5j4o9PO3WNyr2TYRiV/ULcZaTaXBfFBUfPcV8TeOtxc41pj0DhxCcTarbMlLqoG7lLW8bNCNGm2Muotnuo0NIwZb3k8sK7O5A2BgH45G+fxW9XO7NQpe3RZZiclcrkkRNS3N0Vp377LLrdfZOZHLJ5gXo3PTGTE8gpNs8eV9xnadfpwOn1eLVzELc94wjQ8685Hcs9z+8OiHsyk0Mml0dvMoO127uVyN32Oid5V3Tnul0467uPYPU2Rwi/+JYjcPW5h7nHKRT3nqEM5nuRe9Zrt2k/B7MI//HpHcbXJT99dAvW7Si+Dm0xrrt7g2cVVULKvS4jXah8NEhmckXnazDjz34h7tIWqIvZePcJB+HwOc24+PXzir6nnMi9P5Xxsl+a6yKO557LwyLnXEC4LdNlSMcMO2W/NxNTesiEPz3jr2Mqs0IGDRHei7t6sb1zKCDuQ5kcfvrYVry0uw+Hff4edA9mUB+Tdxo573jZnMCuHkfc9Vm7C1oakMzkvQU8ZPQq4IvpkXObcdqhrcjk8vjanetx0Q8fw+a9A4hHbMeWcTsrPTLd3umkiZ5x2Ew0uvbWMV++D2u2dfmfOZfHvoE0Zk9JoCFmo2coEzojVY6xDHft8a/c8SLe8oNHQ7e/1jWEv2005w+MZNnEdK5wLGWicOnNa9D2Xw+MdzPGla6BNNr7kuPdjFD2C3GXVknMtrBkVhPuvuIUfPufjyn6nrAsGpX+ZBZrtnVhYWsD6mOOtywjU2mB6BNpZFZHj1HczeeUVo60Kwo8c/ccA6msd17J/S/uwQPr98AmCmx7rWsId63b5T33OqNc3jteLi+wpycJIhSUGTh4RoPbFmffvX3OnUBe+OJ+8wffiKl1MWRywYHBWMRy1rXN5vHS7r7ARDDAj68TUdtb9hAAfv2EX1NfRo0zm+NorouiZygTKoLyLqWaA6oqA+kcLvv108Zt5Wb+mJCdVVh9/fFk1UtOZzYRO56x4riv3o+l1z443s0IZb8Qd/lHUo7VIiknct83kMZTWzpxyuIWRG3y8txjtoWIZR68LGbLhJUxlncHUtx1i0LWhhlM51AXtXHNeYfjf991PFoafUFWI3fAsSL+58GN3vN61XPP+17+7t4kWhvjBdduQUt94HlHvxvBKAOsTYmot2ShOpGsayCNeMTC2h3dOPv6R7CnN3h73+92ZomoHag7L/1/AGh33zOzKYEprriHiaC0q0rlb5kGbcsVL3VsRGXQMPmtUnJFZtoOpXP44cObKiqSlszk8Nt/vFqyqmc5VOPzMaPD/iHubuReibiXs+9TWzoxlMnhxEUzYFuEbM4R93jU9qJk3SqQUbhplmyYt9qXDNoyOlklcm+IR/DhUxfivKPmBNZO1cVdR7WR/GyZPHb1JI3jEgdMqQsIthRbAWcxj6ZExDtnJpdH12DGS6Wc3hhDPGIXiLpEzjat0yL3Paq490lxdyL33mQmVOA6+v226QTLFhTuUe5qUXlhnnFbTqnoUhRbFvL7D23Et+59qeS4gcp37nsJV/5xHR5Y3z7itpmsQGZisH+Iu8zKKLFQtEo5kbsUmBmNcWfdVbf8QCBy18Xd9c9NtkxYFUk58SkZUoslp3jucmAUCHYWTipk+GeKWI5VklLWUO0azGD11i7jakaWRQEfXgpoOptH71AGU9wSA1HbQl4AnQMpHDV3Ch7+9HJcc97hBd/FjEC1yQwsclbQikf9/Xb1JL1oU6YfzmyOY0pdFL1FbBm5rylQ7QmULSi8/pVU9jRl+eiW03AodvcgxbW/gk5EXo++ZAaD6Sy+c99LZc8Klsjvr9jawsz4sl+Iu7y1V4WvFOV47pKYbSHi2jLpnJPqJ4VUXzZPCow+ExUoHFiUf0Ay2k+F/AGmsk5GykDaidwlaqQfsamgrr2K3J7O5gORYjafxyfOWmJ8z0zFh5eC0T2YQc9QBs1utpC8Dh19KUytj+LglgY0xCOBuwogWKytezCNuqgNIgpE7oPpnDe4LAeyZjTES9oyshM2ee77Bvy7B5O4V1JZsnswU2B1yO/UIqeaaNjAazGKee5ynEZfkKUYMitLCOCXj2/D9x/ahJ89trWiNsVtKe4cuU9U9gtx/+pbj8Sn3nQITlw4o+z32EWiXJ1YxELEImRyAoOpLOpitmeBZJU1SUuhR09SIKUtE1Zo64H17Vhyzd0YTAUjd7UzsImKdli2RYhFHAtFvduY0RD3JgrptBrEvWswjR4lcpcdSkdfCtPq/ei8Tuto50zx8+i7hzLedtVzB3wxae8p+LzhAAAgAElEQVRLYXpDzCuF0JfMhtoyUm837OrDmm2d2NTej8/8fi3S2Tz2KQuOmGyZSsR9+bdX4Zv3BssTy2qiEdvCuf/zN7znJ095257YvA8v7S69iHexyF12nnpZ52LIX4GA//3srnCRdS9yZ899wrJfiPv0hhj+/cwllS2qbRVeGjXbRD1U1LZgW07k3pt0hE0KaUdfCkuuubusc+qeelMiAqLwRSl0BjNZNMT8yF3tDCyLYFuE9514kPG9EUuN3H2haEyEr+eiRu7yXKlsHts6Bz1/XV6zvIAn+EDQhgGAOUrkLoQv6nWauMvIfV9/Ci2NzjGa4hH0p7KBGjYmXtzVi7f/6HHcvnYnfr9mBzbs7g3UxzFG7tnyRRMAfrTqlcBzWU00avjtXbLyCZx9/SMlj1lO5F5J1oo/Y1dghnsN91ZYMVPeefGA6sRlvxD34WDy3FWhUYXKsWEcz11aEnKqv8wDL4a8ldfT5iwCGmMRJRWyeBQ5mMqhXrFlVL84YhGICF++6Eg8euXpBbZIxI3cdVtGtXl0wlZh6uhL4fiDpjnHVaygafWKuDcG39ukdSJS3AsjdzfbaDCDqe6dgJww1ltmHRY5k3fD7r6APTZSz92EvNNQr0MuLyoqNhY2OQvwg4zKbBn3gfBFurPEkok6cfd7mei2zN82duy31UBZ3EMwWRj1SlTcrIh71HZsmWxeoHcoiyl1UWWqf2lxkFFvobgTmhIRr1SBGrmblgLsTWa8lEYdNYd+3rR6vPuEYARv227uuWbLhB0PgFfdUXKoMvAq11pVff6pii0zXYvcj50/FRcec4D3vK5E5K5aP/LuwjRD18Qjru/90u5gqYOReu4S1XeXka2aqdSXzGD9Lt+O6U9lsc0tq2w6RrFFR+TvNJsXuPWpV7F170DovhJf24W3Dm+xhVdMyO+1GpH7LU++igVX3Tkqa96+5ydP4foHNlYl7bPWYHEPwbLIi3BkdKP62aqQxSKWlwrZm8yguS7iZcuUIw6D6VygoqSECFg0sxF/fHoHzvjOKuzs9n1RU3ri3v406uNmMdbvRPS0yDBbJhEN/4novnnbgmk47ZBWNCciOGRWo3OeiH/eqUrkLi0VSVMiiu+98zjPy5WiHtfO/417NuCpLZ3oGcpgqivuMuovtQiLRF7nl/f0BQaxz/ruI7jzuV2BfU3fX6lCXqpQymwWVVx6hjLeUo0HzajHv974BE771qrAMVRLrZjlIjd1DaZx1Z/W4Q9rSqdEyt91Xvhevazw+fdNe/GvNz5R0ubxs2WGF7k//WoXvu2OT1x754sAgovQVxtTAsNoMpDKYsFVd+I3T706pudVKVvcicgmomeI6I6Q7e8goheJ6AUiuqV6TRw/pO/uZdsowjlLiZyjNiFqOdPpB9M5NCeUyN0gDqqlAzgRu4wgF8yox+KZjjBaRPj+O4/DsfOnYnPHANYq9U30Y0hUz12lUNypYLtThjcfiKB0AVc5cHpw/dr6mI2fvK8Nj199pufrRpSxC2mfAMD0hnjBewEg4YqGFHXZscrB8Od29OAdP37ctWXcyD0uxb386LOlMYat+wYK8rS/dtf6wHNd3F/dN4gjv3hv0WNv6xzEvv4U3nHD49jc4UTS6kpRvUNZbHEj9bqojecMdWuCK3yFC638fW1wB2bLqSApl0/M5PKe5dPpZg09s70bf39lX8njxEbouf/T//4dP3h4EwB//kGmzDkFYXQOpHH0l+71SkcDvm1V7cqdqg1muiuQczJ+/NdXCraNFZVE7lcAWG/aQERLAFwNYJkQ4nUAPlGFto07UhClwMjslfOPnhPI045FLNg2edHPlHrfczcNguqDiUPprLffB5YdjC++5Qhv29T6GL558dEAEIjcG+I2tl53Ps46fFbgWMON3KO26rkrkXskXNxPXDQDN723zXteF4sgYlsBn149j2rjzNAid+8uye1IZSdFRFj/lXPwP5ccG9h/KJMr8NxN9XrCWH7oTKQy+YLvRx9H1zOUtu4rbXsk0zn8bvUOPLW10yvupkbCPUMZ7+5BvVtTRUIV/P5UFpf/5hls18ZvPvjzf2DlI5sBABvcO4FSYtubzHgdQiqT92yZvHAK0MnOrNQdp/w1lZtf/1r3kPFuIJcX3joGsl13r9uFlY9ULoqPv7IPvclsQFCl/be3yuKuBm3F7nJMxQDHirLEnYjmATgfwE0hu3wYwA+FEF0AIIQY+dS3CYD0M2UU2ZyI4q+fWY7vXXJcUNxdz13+bTYn/GwZ022rPhA5mM55fntd1PbKEEifXHYG7coPtC7qiJ8egauR+58vW+Z1THppA13cbcsvw6t6vIkScwNOO9RfC1f3xwEgptgyDUrH06JF7rI90gaa1uBH+XUxOxD1S6ZotkzXYLqs+QmfPedQ1MdspLJ54zgH4Cx5eNQX78XGPcGFzItNBJMks7mi/rFT5Mxf41YiUzH7U1l84Of/8F6/47mduH3tTnz3/uDA4IMb/D8zb/nGEjNGj/7SfV4lz7QSuQPAd+9/2V+isIS4+8XqSkfuu3qGsOy6h7Doc3cVlFbO5PKetSSrhH7010/ja3dtKHlcHWkxqeNLMgDoqHIFS7XTn4i1f4DyI/frAXwWQNg3fgiAQ4joMSJ6gojOMe1ERCuIaDURre7omDCr8IUic91l9BqNWDhoRkNgKn/UdrJQVPuhuS7ibTf9+Gdpg6GDad+WiUctL8qWv9Fp9bGCipGyw9EjcnVc4Nj5U/H+kxYY99M7BdVzVydemQRbf5/p3P52/7o0BAak/cfff+dx3qLkcfdaq4OvgNn7122ZvmS2qI0EAFecuQQfW77Y6ciy+QJbRgrDb556FX2pLP787GvBA5Txd5zM5IuKY0DcDWvNPqpNdJJlGsKsOJVKZoymMjkvcl/Y0oDHNu312lBsENfZnnfPVzpyl5VFJYHB4rzwrulIM5PkcdU4RmZoVTtyT2WLD8RPBEqKOxFdAKBdCLGmyG4RAEsALAfwTgA3EdFUfSchxEohRJsQoq21tVXfPOGQwiSjdFUQZUQsswbUiM5JhXQjd0MkNatZj9z9hbYb4xFPiKXQWBYVeNRSVPWl+fSOQ3Yy5QyoRm0Lg+kcXuvy7Z9S4q7edpr2Vc+j2jXyff/SNh9vUbJkpGhMr9dtm8KIWY/cgdKzkOXdg8wM0iN3Ikcgd7uCql+nsBIQKimlbLKJ3mTGWzDFlK3z8IYONCUiuOvyUwD4s3GnadfERCW1bFJK5D6rOYHeZNYTWFVof7d6O555tQvbOwfxxOZ9AHzxLydy1730wOplubxvy4zQc5fHUX/r8o6v2pG72lZTRzgRYvnwJGafZQAuJKLz4Cx83UxEN2uLZO8A8IQQIgNgCxG9BEfs/1F4uNohonnu6sQmKepRd5sawU6pi3r7DhoiKV2A+5JZL2JtjEe8yVaqnrU0xgKLI0jh12dVHndgsE+VnYyujQXi7nruW9xUuvnT67C9c6hkJKxi2lftEPV6MluvO79gf/mHr2bWhDG1zhG7hpgz2UuI0p1RnXv3EI/YyOUF+t11WKUWW0Q47VurvGvdpaUIDqVLC1Aykw8dHCSCWyrBn/QlkYK6rXMAh89u9u5WdnY74q5GiGGpfaYZo/v6Uzj7+kdwozI+AgSLxE1viOHlPX0FnvtDG/bgs394Dq87oBmvdPQjmclj63Xne+0vJ4VSty2C9Xz8ohCpMjrOYsgbTtWWyWu1iKqF+r3pJUYmCiUjdyHE1UKIeUKIBQAuAfCQJuwA8GcApwMAEbXAsWk2V7mtY46MAGS2jJrWF9Mjd0Xcm+v8yN1UNU8X995k1isx0JiIeINVarSqD0DK8+m3hLo3LUVcj/B179h2C4dJZKqnPtmpGKaouZJKnIBfi0XPgzchOwDLIjTG5BhE8Hx6hyLz9uXr3UOZwJwFixDoRNUyw9lc4QCsCbn6lE7UJsxoiAVsGXUwTkaATmVR356T+6jCHVaKwvR7u/v53djbn8avlHr48hhSeKfWR907Clfc3TuLPz+zE4BTHkJOosvm/Pc9t6OnZMSti7Zc0wCQnrv/udU7gUomZgG+564GMmoRvHJY9VJ7WZ1MKlMicp8AefXDznMnoq8Q0YXu03sB7COiFwE8DOAzQoh91WjgeCIF0IvcFeHwPXdpewTtB1/cwyN3+SPsHcp4qWdN8agXRaryK6NUiRwPUH9Y5x01u+Bc3vR/7e9PLyImZ6gCzh+6rAVfUeRewpYpB5nrrHvuJtQOT05kKjYGoT6Xn79nMO1lQQGFC6aoi32bbBwTyUzeWAohaluoi9lIpnPGsgZS8NPuOrP6Z1EtF5O3nohaxhTGjXucNMmFLcHU1XTWF9bpDc6iKvLzpgsGfP32dg1mkM0JNMYjGMrksO61bhRD73DUiqjZnPASEfRaP5V68MIwoCrvMMrplNdu78b7f/YPfL2MwVy1bSZxnwg2fEV/eUKIVUKIC9zHXxBC3O4+FkKITwohjhBCHCWEuHU0GjvW+LZMUBAAP/KTwq9GwnVR2/Pri3nuTfEIojahL5n1FqhwRKowAjlgqtMhyGhVZr/IH9mP3nU8fvDO4wvOFRa5h01iAoB50+pw4AynWNhBWi57MUrZMuWg2gTFiNoUmDEs/Xz9jkTvcGQb5YB0z1AmMLhLRIFFTlS2dw6VJRKySmdhmy3EbKesskm45HtS7mpeES0vU43cTRH6obObjTbgS6646xF2MHJ3rrcUV7UtQLD0RddgGplcHictcuYeqMsfmtDHAXqVDlO1NFLZvJdO7JyzMptGfhY1M0z+nsLudFTkXIRXOvpL7BksymeyZSbCClU8Q7UIEW8SU2Hk7tkyBs/ddot0EZk995lNCfe9NpoTUfQlM14n0BC3jZH7x09fgr9ctgwfOOlg7xyA/0fYoHj1gc/gtlm/SyzIlrHJ66haG+P4yKmLcOuKE3DykpaCY4ZhFvfh/cSmGTz3Wz70RpzvLnCuC7D8jnRB1NskOwTZkXUr5YkBx5ZJZXN4/0kLCuYQnH39I4F0VMnW687Hbz58Am7/+DLEbAvJTN54x+YsL+gsDG6sY5P1BxbjEbswclcE3eStHzGnCYOZXIGdIcdRurXaO/+3diduftyxaqa7qaeyBLIv7sHF2QGnA8jmhZfSq97dmNDbqtYAUqNeJ3L3r2+pWko6svNSfwJyTCqsXLaKvNzlOCqpEgOqJnHfVWHlzZHC4l4E+ccVsQ3iXmDLyBmZ/h9k1LKMkbtTEpgQs93aMa7nHrMtxCO29+NSby+n1EdxzPypXnaDPJ/8YYXZJ9GQrBpTnrvsqFqb4rAtwgkVlEgGgPpo4fh8tALPXqXZkNd+0uIWvP34uQAKxyBkuqqe5x5my8jJUkKrVmkRYchd9ESfbAYgYBsAQJtbIO3ERTNw9LypiEctJDM54+Qe5/stnEsg8QdZc97cCZWHNrTj47c4a7XqKYgHzajHQTMaIERhjSI5gGkqz7DTTVP0IvcBc+SuilnnQBrZXN65E3FTSiW5vCgYvCywZUIWSElptkylkbsn7sOI3IUQ3sxd/W+l2LkA80pZnv/vPr//xT048esPYdVLYzcFiMW9CPIWX97mqQOqcS1y1z149f0m6qI2YhELzXVO5N6fyni+cd4wMCR5xxvmY960Ovxz23wA/h9H2EzSSmwZGfVOK2Mw0/iZTJF7BWWWAeCDJzt3JmHlmWUkpkfu0mbRr/lx86cFnuueOxBMpczlBbJ5gbqoXdCBAEFhuv3jy/C7j5wY2J6IOpOjVE+82T2+vzC4Y9vog9UBzz1qGdcUuMOtfaPeGRwzfypWfXq5Z00FB15zXgSsR+4SInh1emQHIO8i5MChOoDYOehE7hGLELetgHBed/d6vOHaBwK+uj4+oA6oqpk06Ww+sJRiKUHuHkzj9rU7vc4kZRB3efxiHcWvntiGg6++y1vXuBxxrzRyf3a7Y12ZSk2MFizuRZCRk7zNUwVBncQE+JG0mp1RbLZkQzziLTTRO5RBfzLrTcY5fLYzoedjpy8ueN+8afV49MozMHeqs7iFFAS9wJbXBqWeuorJlpGiUM5kGRPVsGU+f8ERxhRJyfEHTkNd1Ma/nxFcHcqP3P3zPfip03DeUXOM7VGFVb1LkCJQF7ONvn+PsrA5gQo6oXjEQiqTCwiazGCKutZXKut47npmkyeo3lKNYR1cPhC5Z3N5EBEa3OuvetyqZdITUnvHJgpkDMlzAH5e/2DGP05nfxrZnEBEqSQquWvdbudcSkeiR+6yyql6HgBIZ3PenQTgfxfb9g0YUxk/9bu1uPw3z+AXf98KwLeOVHHOegPDzv9CCFx39wasU0T2N086xb02uJU6y7HLVZvKFLnrHYS8KxjLJBoW9yJELCsQPat/bL7nHrQDTBk1JuRqTY7nnkV/yhf3KfVRbL3ufJx+6MySbZSRSZgQxDzPXU+FLIzcZbSlZ+aUizFbZpi2TBitTXGs/+o5eP1BwYhcpqvaFuH3l56I//v4yVjU2ljQ6XkDqqq4K8Imo8q6mG0cWFWtDdOgaCJq4+GX2r1CXoB/ZxCVtkzW8dybtRr2auQeM2TLSLoG0oHIXUaOMnJXM2ZUfzssHdC2qMAG27p3AAuuutMrfKbWe+8aTCOTz3v1iNZs7cJ/3fEihBDe72x71yAWXHUn/m/tzoLIPWDLZIO2jFo/SYr7ad9ahaVfe6Cg3XKBkV5vGcrCuji+LSPHDvK44a+v4O0/+ru3jyx1IYu5lTMDSbVlTCt46ZG75+eP4fQmFvci2JZT7VF2zKpQ+XnuQV8+pkTExWyZhpgfuXviXmTVo1KEdSQRz5YJvq6nQtqW5d2WDjdyN4lRJWvRjoR41L+TesOC6Thq3hTndeU7+/F7Xu8JtnqHpc6cleJdHxK5dw9l0BCz8f6TFuDY+QWTsJGIWgUiKoVT2jJO5U1R8H1n83nPFopH7MBdiHoZ9w2kA2M5MltDlndQxVSN3MOqZtoWFSyW8tgrewPP1fPt7B6CEP6i6i/t6cNNj27B3v60J12yc/vi7S8UDKg+ucXPklaj+nQ2j109Q95Yh1qawRTxymQFeQxplag2SSYfjNzlPmrHLMcbNrl1hPSoO5nJYcFVd+J7D270XivblvEnrYR+jtGCxb0IEdvJepFfdiByl2KuZcsEbZng5V3Y2oBvuRUeWxpjmFYfQ1PCmTzSn8qiqciqR2Hc9N42fPDkgzFvWp1xu7Rf9EhCHT+Q7T/MtYMWzSw//bEUMdvpwK5925FVO6YJNXIPe/3s1/nzANTvSb3jkHdCddGI2ZYZzGDRzEZ86cLXGTuzuGHso1GJ3GX9nnQuX7DYSTrr1/SPRayAoKtfX+dA2lu+D/DFZbqhwJyMai0KpiCq2ERIRO1Ah29KtQScGdQPu4OC+qLr2/YNeOIlJ4J1DqQDg8uLZzZih1LeQr3LSGXz2NWdxMFuPn6pDBfZRjnxLW0Q7lzOj9yFEMZjysv8cru0ZYLvkee58W/+vMxAbZkyUiHlOcYyQZLFvQjOICN5X4g6Y1RWO9SzZYK2TPCP/0MnL/QGQr/x9qPx9X86Cs2JKAbTOXQPZoYVuS+Z1YTPX3BEaGnR0BmqWscjBPDvZyzGPZ84xRP5amBZhHVfOhvveuNBVTumCX++gWV8Xf9jU0VYzXOXhNky6Vy+aBlkmZKpdtReIOBmQ0lbRo+WM7m8J1DxiBX6nb7rpidx7wt7vOfysy1oceYmqKsxSX9bpt+akAO36phJWAGy95+0wLMh1IlvALBt36BnO+xRvPPNSt64zI2XqIto7BtIoy+V9cQ9mc0HRFS3FqU1Jf+X+6qRtOys88KxT0zplfLuRh4+L5xO6dD/vAc3/m2z8bjJEjNU9QXL/aUN2ZaZENiWhYjtR+7qKHzMDmZdSCEPRO4GX1syszmBWc0J7w98V0+y6Hqlw0WeU/9N6bZMTjgDZMMR9m//8zFYcerCYbexGsgIXbeBTJE0EPyeTGMM9TE7UHY4cK4is3ZlEHfZGYu9QW91sN2xZXLI5ETB953N+2Kml03QUScOyTuS+lgEs5sTvncMeOvv6sXqVGQ2mJo2qto56jVV5z3IAVWJulSgWrZhtyL08k5Obx8AvNLudAIHt7rinskF2qGvpiStogHNllE9dzUbJ5XNGQu/qW0AnE5EZu38fvUOv+yCEqGr2Tem8s76XAO14xgrWNyLELEItmV5X5SqG/okJll+IJAKqQmNKb1PDubl8qIgkqsGcpygIBVSs2UaQhb5KIeLXz8Pnzvv8GG/vxrIaFq/wmFZRKoXbxpjqIvaiEdsNCUiWNTagHs/caqyLfzPRtoMMxpiBSVoY64YJjOOty4rX771WKcqZiYrPIHS0yQvO30RFrizhiUtjXGs+c+zcM35/rVf0FIfjNxd4ZppWHNXIjsfNXJX6+uoA85q7n9Ut2U6Bz0RC9TkURQtFrECg7f9ing/tbUTAHDKYqdi7L3P70bbf/kDqWrGTFa5yxnSxT1Qryfvfb6kYXEWoHASVl74YpwTwntPJiRyN1UAlZ9Z/h7LXQSlmrC4F8G2HVtGrRgo0fPbPc+9SLaMaXBRFfThDmQWQ1anLJbnfv9/nFr0tr0WkHaIfoccVvgsELkbZsNKoZvREHOymhTrpljlSWlntDTGvd+NHHh9yzEHIB6xvElG0xpiWPuFN+Nqt2NM5/KeQOmR+0mLWrDqM6cHXmuI25jRGA94/we3NGLrPn/Fpt6hLGyLCiZkHTqrCae4Ubgn7srnUvVK/V1OUa5VRCs2t3XfoNf+PVoNd4lzLRVx16LxI+Y04yDXXlIXIwGA9l5f3NX1VnVbZu32btz/omNb5fLCSxFNZnJFbRlJWlnERQhzjrx6B1BO5C7PW05tomrB4l6EqEVBW0adfaoVFfOis4AtU0bkrkQxoyLuEbMto5YvXqIs9l2ryO9B/0PT7Sfv9ZBUSIm0KKY3xBCLWAF7J1FE3PsUcZf+8xFzmrHp2nMLl2e0LUypj3ptDHruwXPI933m7EOVNhbe6b3ugGZ0DqSx2o2Ce5MZNCUiBXMQYhEL86Y5IirFPawWvpqyOa0+5v32IxYFOs+tewc8iyNsRSgncveP168J6ylLWkLHNGRdeyCYy68PqPYMZfDhX652F54R3nyCVDYscg/aMkOZnNdh5PLCKMjJTM77my/Hc5cdT6WzbkcCi3sR3nPiAnzm7EOVcgD+Nj1yl1+w+scbtcY/co+ERe6RwrbUMlJw9drhRIR/aZuPX/7b0sDrqiiZspRkKYW3HTcX5x81J7ASVDH7TIrVjMaYF/3Go7afKqv+Pmw589n/DUkR0O84ZAdw2emLvZouDQYxfvvx89DSGMePVjnriPYls464ax1SLi8KJuDVhSyurnZ+UdvyJ4zZwQHVnqFMSU/Z8dz94+nCuWRWE6I2Faw8BgRtGXXCne65S57d3u1E7nE1cg+eL5cXGEjnAplLjrj7E6JShmg/lfGznWS2zBOb93mWmDqAr3YQQxXWyxkJZYs7EdlE9AwR3VFkn4uJSBBRW9g+tcTrD5qGi46d65cDUBzdmG1h6YLpOHKuk08tvbRokTx3U+pc4JZ3VMQ9bIbq5OrXPXE33CJ/4+KjceohwZW/1Ijesgi/+uBSrygZACRizvb3nLgAHzltkVauIPx7kt/x9IaYFxSoHYMakUe9AMGv8JkOsWXU5zLCrjd0SnUxG0sPnoZt7mLaHX0pzGiIF4h7Xgiv4/ci95A7Ev3ORg4oR9zUznKwlDtb1eLSxX1RawPITc3U6R7MoL03iX39KS9ab2mM+Z67Jpz3PL8bubzw7nDW7+oN5M7n8sKzheZM8W3JZNqP3PN5YbZlMjkvKJCB3SUrn8Dyb6/yjg04wcXSax/An55+zXvfWFHJX/gVANaHbSSiJgCXA3hypI2aaPjZMv5rRITfXXoizjnSyVSQubUx5Y9Xz5bRF6kGglGgqVjWSLE9cddTISdb5O5Gv2WmI+hphqcsafWKgAGGevfKc31mqcqtK07AZ84+FImo7Q2oqkJlurOT/2cUz70gcjfk5Zsid6d9UW9m6p7eJGY3JwpsmWPnT/UjdyocUNWPp+JVSVVSIU3zLFqU2jwyrTRqW3jzEf58Az2ffmFrI4DCzx+xCF2DaSz92oN4/X89EBjbcAqxBdMmAeCnj20B4K+x+5k/PIdHXvbXp130ubu8WdmzFXFXI/ecEMYMm6FMzktdNg2SSnEXQoyojPFIKEvciWgegPMB3FRkt68C+CYA80hKDSN1MSzvGPB770Tgj7d05K7eDo5G5C6brA/wFPsstYiMiEdSR1tdXavY9TF59JIj507BZW5NINkSVdzj6oB7RNYucibLZYpF7rYhci9io8gsmd29Scyekgi04c7LT8aXL/InYflzNMyfWf4u5XnrlIlhsp2HKOM2sjSEeoejzgw+58jZeOqaMwH4frl+Lj1ynz+9Hl3KDNu9bjkEedzBTC5gy5ywcLr3WM0Ee3Fnb+C4e1wf/4ApfueUzQtvfkAuH8yMkX9HyUzO+3xZQ3Qvg6l92jKEE07cAVwP4LMAjIYRER0HYL4QItSycfdbQUSriWh1R0dHsV0nFB9Y5lQq1OuZqJx/9By8c+l8XHXuYd5rerRsqjanRoSjIe4ywydM846YU70JS+OJTHk0DW6VixTQA7WUQ51y77Bk5K5GoWpqpmqN2Rbhhw+/gl8/uc19j3lAFfBFPSx9tTkRQTKTR89gBn3JLGY1JzCzyc9zf90BU5zyBnq56hCLJUzcnRm3zuOp9VF8dPki/PLflnrZQaoV1NIkI3fnXDPcBd+lLXPukbNx0bH+Qum6uM9oiKFrwB/4lLNk5d3BYCoo7q1K9pc6n0Bf81Xms6uRu7Of4+/nRVC4pdefVDz3bC4fqJcD+Csx6WWWx8GtFfkAABV5SURBVDJbpmRiNRFdAKBdCLGGiJYbtlsA/hvA+0sdSwixEsBKAGhraxvLmbgj4sRFM4pWKgScH+PX/+nowGublXxjoPQEhmIR4XCRU9JNk4we/vTywK1zLeNly4xgsWI5RqLnk+uUOx9hyawmPLWlsyBDRqKKu4zYH37JCXqKRe7SPgm1UdzfkVyBaVZzHGcdPgvTG2IBa1HeWcqYI6w8s/TI5fm8CWPKgGoiauPKc5zAZqs7mUmtKSN/Z/J7si1n0FRG7leecxgWKMsA6rbMtIZYYKbrU1s63eO6kXs6G5hVq6Z+qnfHav494KdXztHEXdaVH0rnAoLcn8qiKRFFMusPwmZyolDcQ2aiVroAyUgo51e6DMCFRHQegASAZiK6WVkkuwnAkQBWubeyswHcTkQXCiFWj0aja4Vtbr7xIbMa8fKe/pJ1osOqAI6ERNQO7ZgObqleDZnxRg4OVmLL3PjeNm/5QsCZJQwAB80ofl3K7YRXvuf1eG5HTyDSN2XLmCjmucsIuiHMlnHP944fPw4AmN2cgGURnrj6zIAN4q3S5T63LXPkLrNj5Pn8wWvhFcpTO58Dpzudo7rwRqviuavnl8KpVw+Vi6m0NMbx96vOwOf//DweVvL3ZVqkvCPoTWYDkbsq6MVmfktbZs7U4JiB/C0MaeWb+5NZYIozeJuIOqtlZfP5QPVNAMiFTFbSbajRpKQtI4S4WggxTwixAMAlAB5ShB1CiB4hRIsQYoG7zxMA9nthB/w/UCkWE2FF9MmKv+xg+df4TUfMwusOmOI9X+QO5p15WPFSy+WK+9T6WEGWTiBbpkimSVnZMiGRu35nMWuKXNbRCkxCkp2L/F2GdTbyPEcc4Fh40m4ZTOeUGdr+e+XvXZ2gJBc+iWljUlLs9LsGOXZVF3MmSk1tiAYGy2UELCP3di0ir1csq2KTzmTkfoAWuaulFPb2+Z2UHMtIZnKoizk197PGyN18vmQmh8/dtg53r9sV2qZqMex8OCL6ChFdWM3GTDbuvPwU/PLflnrZCBNgzdxJSySk+mUlnP262Xjyc2fipMXF140tli1TimDkXr64q9lNdVHpuZfOS5/VHA+tGKrXHdLbI9exXdDSgJ++vw1fe9tRzvldsR/K5LxoX9XmuVMLz6f69N75lchd9/vl3YG8I5ClGlRsi7y1X/doi3modzWzmuN4zwkHeWMBEYs8MZd3ALrnri4aopZi6HCFPpnJIRFx1mQw2TJ6AoNkIJ3Fb556FeuVev+jRUXiLoRYJYS4wH38BSHE7YZ9lnPU7rB4ZiNOPaTVW8kpzJb5+1VnYNWnl49dwyYh09w//mPmTymxZ3FmFanBIgmzQ8qhXHHXbRk1e6dU5K7aQI9fdWZo8TTbs2XcKo9a5C7LIhwwtQ5nHDbLE9xL3uBUNl26YLr3Xr00xylLWnDt24700ib1WkxA8E5Bv2vw3+ecc5pB3JsTEe+zyYW1ZWdQH7MDC+h89a1H4k1HOAueN8QjWPleZyrOnt4UojYVlF9W2TeQ9u5M2vuSEMKZlJSI2u7KWrmKPHchgOmGkhfVpvqVqpgC/IV3zdsPMEQ6TGXMak7gzstP9qyV0SRsfddyCA6oFh7nm28/Giv/trno5KC6Up67MkmoWFsLBlS1c76jbT7e4ZaoVnnjQj/BwNMw7TS/+uAbAQBvOnwWugYzeGGns6xd2ICyfm4p2rKTm6OMjRwwJYGdPUlMrY9522UWjFz2ryEeQdS2kM3nPGGWv42eoYx3Dff0JtGUiHqd5wFTEugZygTKJ/QlMzhgagKvdQ2hvTeFW/+xHXnhdECJqI2hTC6wdKAQouQd5HDXKa6EyTVNcYIio0nT7SpTPV53wJSidV8mAmGpkJJ3vGE+HvjkaUXz7P0ZquVNOgrDX6XLEaLhDOgLURi5q8xsTuDQ2U2Y0Rh3FuJWC4+ps7kLFlkJRvpqGvI8d8C2uS7qbZf55FLs4xHLO74cbF880+/45TWU5RkAZ83dOy8/xbt7k9ejP5VFfTSC1qY4tncN4uo/rXPbaKMuZiOZCUbu6Vw+IO6myWamO5Fqw5H7GPChkxfi5MWt3oAUU5tcec5heEVJxxsOU7Q6LZIZDbGy6/n7M1TN+4fZNTr+gKrz/IzDZuK6uzfgmxcfjcNml1dMzlR3ycSpS1rwwCdP84qVAf7MXKLwFbSkWKsTtma74jtFEXe5xqta80neJUiRP0hJcZW1gwB/AFpG9vLc0xti6OhLoT+ZxezmBGZGEoGFtRNRG3VRG0PpoLgn00Fxb2mKY2DfIKbURb39TKt8VRsW9zHAsoiFfRLw0eWLRnyMlsY4rjznMPzq8a1eATAAeOqas8rOppo1JQGL/DRAHSLCh085GKcsaTVul8iIVp71kFlNJedz6JjKYYe1SbfMpOhGrcIZwfqAKgD84t+W4tGNHV5pgKl1Ud9zdycdqd5+RKleCQQ7U3WOgO63y7TMFacsxLV3rcdA2vHXmxIRPLDeIO6ZHHqG/IyaoUwuML7WEIvgoU+dhv5UFhf+4DGn7ey5M8zk46PLFxV0FE7kWp4tsvyQVjz0qeVFbb5rzj+i5HGk+JWaf1EMr6jeMMpZyM7FtJB8wjAAe9ohrTjtkFZ8/S6nxFUgcpeeu+1H7voSmICz5nAsYiHqro+cU0oCS67/l2Oxo2swkEKZiNqBWa+A820lYjZ6hjJIZ4PirqZtRiMWFrY2BhYo58idYfZzHvjkqQULWxNRYDbncAlbgrESZLrkcLI/vJLHhrEHOYnJtNygtGjq4/6i3vsG0iACPvXmQ3HpzWuwZFZjQOglZ7kZM4BTBbMvlS2YF3BwSwMObmnAs9u7vdec+vfBznRPXxJ1UQvtvU7pg1jEWfx8MJ0NpELKgWvVkiuWe18tWNwZZgKzeOboLaQS0VIhh8O7TzgI8aiNf379vIrfG/XEtzByl167KWtI3iRELSswbtCUiOCcI2d71pIpclepizniHjYArQ7yxmwLSw+eHth+xmEz8fLuPgxlnAXu506tw5a9A0hmcgHPXd6ZqHc3Y1G4j7NlGGY/RU+FHA4R28I7lx4YWnSsGAnDxCZ9mylyl5aHbRGI/NWg9EVXZNXNsPLWsqzA/OnmWkJRLW31mHlTvedbrzsfh81uRl3MRn8yi56hjGeTDaXzgTz38Vo7gSN3htlP8SL3cZo5rRYgC9tmEvecWxxORuSxiIVUNu/VV5dIUQ0LkmUu+zHzzBPfIoFJVk4ZhGPnTw3YK4mo7aVhyjpFg+lsIHJXxf2/3nqkVyRutGFxZ5j9lIhWW2askRkr+nKUgGLLGMRdZt3IvPV4xEIfCssx+IugFP98an0h0/sBP4Pmz5ctC34GxTuf49aEH9JtGeXO4d0nHFS0LdWExZ1h9lOi3vq643P++jJsmbhh29uOm4uDWxpw3IHOxCaZDqnn90tbxrRSkkpY6WQ1cg+bMaxOmpORe1JLhdQrXo4VLO4Ms58ibY2RDKiOhLpYMVsmPHInIk/Y1X30lan0xet1Hr/6jKKLuxSbQet9BkXc5czWPz39Gp50680D4XXyRxsWd4bZT9FnqI41vude2YCqjlosTOWLb3kdCC/ghIUzjO+bM6V4ORCTLVPQzlihuKvCDoSvcDXalH1WIrKJ6BkiKlhKj4g+SUQvEtFzRPQgEY2dscQwzLDQF+sYa6QYmwLbYqmQOmGR+8EtDfjZB5aG2i6l0AdUTaiR+9yQ0srjlS1TyVmvALA+ZNszANqEEEcD+AOchbIZhpnA+JOYxsmWiYYvau5H7qWFWXYEpgJdI0EV5VjIQiaquIdNTCq24tZoUpa4E9E8AOcDuMm0XQjxsBBCroH1BIDKZzQwDDOmRMc7FdIVY1Nq4LT6GCIWlbXGbzTElhkpqs8eGrnH/Bz7MF8+ErJ84WhTrud+PYDPwlkvtRQfBHC3aQMRrQCwAgAOPPDAMk/NMMxoIAdUR1JbZiTUF4ncW5viePjTxevnSGT768usqlku6szWMN9c3mG0NsVBRF4JAhWZtTPWlOxSiOgCAO1CiDVl7PtuAG0AvmXaLoRYKYRoE0K0tbYWr1jHMMzo4mfLjA/SC8+G5GLOn15f1sIo8v3VtmXUEgFhtozsF2WFTtMYQVhEP9qU09UtA3AhEZ0HIAGgmYhuVhfJBgAiOgvANQBOE0KkDMdhGGYCISVnvGwZ6VGPdMamFPe6ESx/WIowW0bOVj39UGdR9VjEAjT1K1UOebQoeTWEEFcDuBoAiGg5gE8bhP04AD8GcI4Qon0U2skwTJWR0/UvP3PJuJw/UcSWqQRZjqDakbtKmLgfOXcK7vnEKTh0VpO7X6GQj0WRMBPD7uqI6CsAVruLZH8LQCOA37sf5FUhxIXVaSLDMKNB1LYqXpyjmtR7tswII/ecjNxHUdyL5NsfNttfiMfUCdi1IO5CiFUAVrmPv6C8flZVW8UwzKSnrki2TCV4nnuVB1RVwjz3gv0MncA4We5c8pdhmPGhWJ57Jcj3VzsVUqXcdEbTgGo5g8KjAYs7wzDjgozcMyMUd1kYTJ+hWk3KLf5lsmXGa0CVxZ1hmHFBRu6lqjaWQnru5dShGS7lzjJlW4ZhmP0emS1zYMhKSOWybHELAKBxVD33ciP3QiWfsKmQDMMwo4FtEW58bxuOmmteLKNcvvZPR+LjZywOrJBUbcot/mW0ZSbwJCaGYZhR4U1HzBrxMeIRGwe3NFShNeGYas4b9zMIOdsyDMMwE5RybRkTPKDKMAwzQam0JntLY9yziTgVkmEYZoJSbiqkTOq84szFOO+oOQDYlmEYhpmwVLrgRixiIe/m77MtwzAMM0Gp1HOP2pZXZ368asuwuDMMw5Sg3EWuZfnkWMTCR5cvwiGzGquSETQcOBWSYRimBBXbMraFha2NuO8/ThulFpWm7MidiGwieoaI7jBsixPRb4loExE9SUQLqtlIhmGY8SRaZuEwOaBaaXbNaFBJC64AsD5k2wcBdAkhFgP4bwDfGGnDGIZhJgoVpzOOU4aMSlniTkTzAJwP4KaQXS4C8Av38R8AnEnjtfwIwzAMU3bkfj2AzwIIK982F8B2ABBCZAH0AJih70REK4hoNRGt7ujoGEZzGYZhxo4TFk6vaH/hjqhOhMi25IAqEV0AoF0IscZdQ9W4m+G1giLNQoiVAFYCQFtb23gtus4wDFMWP//AUgylc+PdjGFRTuS+DMCFRLQVwK0AziCim7V9dgCYDwBEFAEwBUBnFdvJMAwz5iSiNqY1xMreX9aot8drWqpCSXEXQlwthJgnhFgA4BIADwkh3q3tdjuA97mPL3b34cicYZj9iq/901H42PJFOGlRy3g3Zfh57kT0FQCrhRC3A/gJgF8R0SY4EfslVWofwzBMzdDSGMdnzzlsvJsBoEJxF0KsArDKffwF5fUkgH+uZsMYhmGY4TP+mfYMwzBM1WFxZxiGmYSwuDMMw0xCWNwZhmEmISzuDMMwkxAWd4ZhmEkIizvDMMwkhMZrIikRdQDYNsy3twDYW8XmVJOJ2jZuV2VwuyqD21U5w23bQUKI1lI7jZu4jwQiWi2EaBvvdpiYqG3jdlUGt6syuF2VM9ptY1uGYRhmEsLizjAMMwmpVXFfOd4NKMJEbRu3qzK4XZXB7aqcUW1bTXruDMMwTHFqNXJnGIZhilBz4k5E5xDRS0S0iYiuGue2bCWidUT0LBGtdl+bTkT3E9FG9/9pY9COnxJROxE9r7xmbAc5fM+9fs8R0fFj3K4vEdFr7jV7lojOU7Zd7bbrJSI6exTbNZ+IHiai9UT0AhFd4b4+rtesSLsmwjVLENFTRLTWbduX3dcPJqIn3Wv2WyKKua/H3eeb3O0LxrhdPyeiLco1O9Z9fcx+/+75bCJ6hojucJ+P3fUSQtTMPwA2gFcALAQQA7AWwBHj2J6tAFq0174J4Cr38VUAvjEG7TgVwPEAni/VDgDnAbgbzrq3JwB4cozb9SUAnzbse4T7fcYBHOx+z/YotWsOgOPdx00AXnbPP67XrEi7JsI1IwCN7uMogCfda/E7AJe4r98A4KPu448BuMF9fAmA345xu34O4GLD/mP2+3fP90kAtwC4w30+Zter1iL3pQA2CSE2CyHScNZ0vWic26RzEYBfuI9/AeCto31CIcQjKFyzNqwdFwH4pXB4AsBUIpozhu0K4yIAtwohUkKILQA2wfm+R6Ndu4QQT7uP+wCsBzAX43zNirQrjLG8ZkII0e8+jbr/BIAzAPzBfV2/ZvJa/gHAmURU9YVFi7QrjDH7/RPRPADnA7jJfU4Yw+tVa+I+F8B25fkOFP/xjzYCwH1EtIaIVrivzRJC7AKcP1YAM8epbWHtmAjX8OPuLfFPFdtqXNrl3v4eByfimzDXTGsXMAGumWsxPAugHcD9cO4UuoUQWcP5vba523sAzBiLdgkh5DW71r1m/01Ecb1dhjZXm+sBfBZA3n0+A2N4vWpN3E092Xim+ywTQhwP4FwAlxHRqePYlnIZ72v4IwCLABwLYBeA77ivj3m7iKgRwB8BfEII0VtsV8Nro9Y2Q7smxDUTQuSEEMcCmAfnDuHwIucfs7bp7SKiIwFcDeAwAG8AMB3AlWPZLiK6AEC7EGKN+nKRc1e9XbUm7jsAzFeezwOwc5zaAiHETvf/dgC3wfnB75G3ee7/7ePUvLB2jOs1FELscf8Y8wBuhG8jjGm7iCgKR0B/LYT4k/vyuF8zU7smyjWTCCG64aylfAIcW0Ouxaye32ubu30KyrfoRtquc1yLSwghUgB+hrG/ZssAXEhEW+HYx2fAieTH7HrVmrj/A8ASd8Q5Bmfg4fbxaAgRNRBRk3wM4M0Annfb8z53t/cB+Mt4tK9IO24H8F43a+AEAD3SihgLNH/zbXCumWzXJW7WwMEAlgB4apTaQAB+AmC9EOK7yqZxvWZh7Zog16yViKa6j+sAnAVnTOBhABe7u+nXTF7LiwE8JNzRwjFo1walkyY4vrZ6zUb9uxRCXC2EmCeEWABHpx4SQrwLY3m9qjkyPBb/4Ix2vwzH77tmHNuxEE6mwloAL8i2wPHJHgSw0f1/+hi05TdwbtczcCKAD4a1A87t3w/d67cOQNsYt+tX7nmfc3/Qc5T9r3Hb9RKAc0exXSfDueV9DsCz7r/zxvuaFWnXRLhmRwN4xm3D8wC+oPwdPAVnMPf3AOLu6wn3+SZ3+8IxbtdD7jV7HsDN8DNqxuz3r7RxOfxsmTG7XjxDlWEYZhJSa7YMwzAMUwYs7gzDMJMQFneGYZhJCIs7wzDMJITFnWEYZhLC4s4wDDMJYXFnGIaZhLC4MwzDTEL+H4MIVIhtuevkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f370671b080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(target_lang.n_words, hidden_size).to(device)\n",
    "\n",
    "num_iters = 40000\n",
    "trainIters(encoder1, decoder1, num_iters, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(encoder1.state_dict(), \"encoder1_40000\")\n",
    "# torch.save(decoder1.state_dict(), \"decoder1_40000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> va mot le khac la viec quyet inh tu nao tot va tu nao xau that su cha de dang gi .\n",
      "= and for another deciding what words are good and what words are bad is actually not very easy .\n",
      "< SOS and s another thing and that s going to be . EOS\n",
      "\n",
      "> toi bi lai thay say sua voi tam quan trong cua cong viec minh lam .\n",
      "= and i was hooked again on the importance of what i did .\n",
      "< SOS i was doing doing that . EOS\n",
      "\n",
      "> gv toi muon thay oi cuoc oi !\n",
      "= t i want to change my life !\n",
      "< SOS i want to change ! EOS\n",
      "\n",
      "> vao nam o phai la phut e co uoc luong anh sang o tu muc luong trung binh .\n",
      "= and back in it would have been minutes to earn that amount of light on the average wage .\n",
      "< SOS and then it s in the to to EOS\n",
      "\n",
      "> co cam xuc cua nan nhan .\n",
      "= there are emotions of the victims .\n",
      "< SOS there is that . EOS\n",
      "\n",
      "> nhung ngay xua lam uoc chuyen nay rat kho khi phai chon cac con con co voc dang ac trung roi gay giong chung .\n",
      "= but we had to do it the hard way in the old days by choosing offspring that looked a particular way and then breeding them .\n",
      "< SOS but it s to they to to to the that EOS\n",
      "\n",
      "> mat khac neu ban mo rong viec hoi lo neu vien canh sat khong liem khiet ban se phai ut lot nhieu tien e uoc tu do .\n",
      "= on the other hand if you extend the bribe if the officer is dishonest you get a huge payoff of going free .\n",
      "< SOS if if you re you to the of that the that EOS\n",
      "\n",
      "> tom thum mieng toi la ca dan nhac\n",
      "= tom thum the orchestra in my mouth\n",
      "< SOS the s the that EOS\n",
      "\n",
      "> la mot muc su ban co the tuong tuong uoc toi a cam thay boi roi nhu the nao\n",
      "= as a clergyman you can imagine how out of place i feel .\n",
      "< SOS that s how i you you that EOS\n",
      "\n",
      "> chung toi at cau truc o vao thiet bi lo vi song\n",
      "= we then put it in this oven like device .\n",
      "< SOS and then we re in the EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "encoder1.load_state_dict(torch.load(\"encoder1_40000\", map_location='cpu'))\n",
    "decoder1 = DecoderRNN(target_lang.n_words, hidden_size).to(device)\n",
    "decoder1.load_state_dict(torch.load(\"decoder1_40000\", map_location='cpu'))\n",
    "\n",
    "evaluateRandomly(encoder1, decoder1, n = 10, strategy='beam', k = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10, strategy=\"greedy\", k = None):\n",
    "    \"\"\"\n",
    "    Randomly select a sentence from the input dataset and try to produce its translation.\n",
    "    \"\"\"    \n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = generate_translation(encoder, decoder, pair[0], search=strategy, k = k)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_translation(encoder, decoder, sentence, max_length=MAX_LENGTH, search=\"greedy\", k = None):\n",
    "    \"\"\" \n",
    "    @param max_length: the max # of words that the decoder can return\n",
    "    @returns decoded_words: a list of words in target language\n",
    "    \"\"\"    \n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        \n",
    "        # encode the source sentence\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "\n",
    "        # start decoding\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []\n",
    "        \n",
    "        if search == 'greedy':\n",
    "            decoded_words = greedy_search(decoder, decoder_input, decoder_hidden, max_length)\n",
    "        elif search == 'beam':\n",
    "            if k == None:\n",
    "                k = 2\n",
    "            decoded_words = beam_search(decoder, decoder_input, decoder_hidden, max_length, k)  \n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_search(decoder, decoder_input, hidden, max_length):\n",
    "    translation = []\n",
    "    for i in range(max_length):\n",
    "        next_word_softmax, hidden = decoder(decoder_input, hidden)\n",
    "        best_idx = torch.max(next_word_softmax, 1)[1].squeeze().item()\n",
    "\n",
    "        # convert idx to word\n",
    "        best_word = target_lang.index2word[best_idx]\n",
    "        translation.append(best_word)\n",
    "        decoder_input = torch.tensor([[best_idx]], device=device)\n",
    "        \n",
    "        if best_word == 'EOS':\n",
    "            break\n",
    "    return translation\n",
    "\n",
    "\n",
    "def beam_search(decoder, decoder_input, hidden, max_length, k):\n",
    "    \n",
    "    candidates = [(decoder_input, 0, hidden)]\n",
    "    potential_candidates = []\n",
    "    completed_translations = []\n",
    "\n",
    "    # put a cap on the length of generated sentences\n",
    "    for m in range(max_length):\n",
    "        for c in candidates:\n",
    "            # unpack the tuple\n",
    "            c_sequence = c[0]\n",
    "            c_score = c[1]\n",
    "            c_hidden = c[2]\n",
    "            # EOS token\n",
    "            if c_sequence[-1] == 1:\n",
    "                completed_translations.append((c_sequence, c_score))\n",
    "                k = k - 1\n",
    "            else:\n",
    "                next_word_probs, hidden = decoder(c_sequence[-1], c_hidden)\n",
    "                # in the worst-case, one sequence will have the highest k probabilities\n",
    "                # so to save computation, only grab the k highest_probability from each candidate sequence\n",
    "                top_probs, top_idx = torch.topk(next_word_probs, k)\n",
    "                for i in range(len(top_probs[0])):\n",
    "                    word = torch.from_numpy(np.array([top_idx[0][i]]).reshape(1, 1)).to(device)\n",
    "                    new_score = c_score + top_probs[0][i]\n",
    "                    potential_candidates.append((torch.cat((c_sequence, word)).to(device), new_score, hidden))\n",
    "\n",
    "        candidates = sorted(potential_candidates, key= lambda x: x[1], reverse=True)[0:k] \n",
    "        potential_candidates = []\n",
    "\n",
    "    completed = completed_translations + candidates\n",
    "    completed = sorted(completed, key= lambda x: x[1], reverse=True)[0] \n",
    "    final_translation = []\n",
    "    for x in completed[0]:\n",
    "        final_translation.append(target_lang.index2word[x.squeeze().item()])\n",
    "    return final_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "for x in a: \n",
    "    x = 4\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2035],\n",
       "        [-0.6198],\n",
       "        [ 0.2603],\n",
       "        [ 1.2791],\n",
       "        [43.0000]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 1)\n",
    "b = torch.from_numpy(np.array([43]).reshape(1, 1))\n",
    "torch.cat((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, search=\"greedy\", max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Function that generate translation.\n",
    "    First, feed the source sentence into the encoder and obtain the hidden states from encoder.\n",
    "    Secondly, feed the hidden states into the decoder and unfold the outputs from the decoder.\n",
    "    Lastly, for each outputs from the decoder, collect the corresponding words in the target language's vocabulary.\n",
    "    And collect the attention for each output words.\n",
    "    @param encoder: the encoder network\n",
    "    @param decoder: the decoder network\n",
    "    @param sentence: string, a sentence in source language to be translated\n",
    "    @param max_length: the max # of words that the decoder can return\n",
    "    @output decoded_words: a list of words in target language\n",
    "    @output decoder_attentions: a list of vector, each of which sums up to 1.0\n",
    "    \"\"\"    \n",
    "    # process input sentence\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        # encode the source lanugage\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "        # decode the context vector\n",
    "        decoder_hidden = encoder_hidden # decoder starts from the last encoding sentence\n",
    "        # output of this function\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "        \n",
    "        if search == 'greedy':\n",
    "            decoded_words = greedy_search(decoder, decoder_input, decoder_hidden, max_length)\n",
    "        elif search == 'beam':\n",
    "            decoded_words = beam_search(decoder, decoder_input, decoder_hidden, max_length)  \n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "def calculate_bleu(predictions, labels):\n",
    "\t\"\"\"\n",
    "\tOnly pass a list of strings \n",
    "\t\"\"\"\n",
    "\t# tthis is ony with n_gram = 4\n",
    "\n",
    "\tbleu = sacrebleu.raw_corpus_bleu(predictions, [labels], .01).score\n",
    "\treturn bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN(\n",
       "  (embedding): Embedding(5551, 256)\n",
       "  (gru): GRU(256, 256)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_e = EncoderRNN(5551, 256)\n",
    "model_e.load_state_dict(torch.load(\"encoder1_40000\", map_location='cpu'))\n",
    "model_e.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN(\n",
       "  (embedding): Embedding(19344, 256)\n",
       "  (gru): GRU(256, 256)\n",
       "  (out): Linear(in_features=256, out_features=19344, bias=True)\n",
       "  (softmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_d = DecoderRNN(19344, 256)\n",
    "model_d.load_state_dict(torch.load(\"decoder1_40000\", map_location='cpu'))\n",
    "model_d.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 100\n",
    "def test_model(encoder, decoder,search, test_pairs, lang1,max_length=MAX_LENGTH):\n",
    "    # for test, you only need the lang1 words to be tokenized,\n",
    "    # lang2 words is the true labels\n",
    "    encoder_inputs = [pair[0] for pair in test_pairs]\n",
    "    true_labels = [pair[1] for pair in test_pairs]\n",
    "    translated_predictions = []\n",
    "    for i in range(len(encoder_inputs)): \n",
    "        if i% 100== 0:\n",
    "            print(i)\n",
    "        e_input = encoder_inputs[i]\n",
    "        decoded_words = evaluate(encoder, decoder, e_input, max_length=MAX_LENGTH)\n",
    "        translated_predictions.append(\" \".join(decoded_words))\n",
    "    return calculate_bleu(translated_predictions, true_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "    \n",
    "Yikes, teh decoder isn't' preforming very well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs = pickle.load(open(\"preprocessed_data_no_elmo/iwslt-vi-eng/preprocessed_no_indices_pairs_test\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lang = pickle.load(open(\"preprocessed_data_no_elmo/iwslt-vi-eng/preprocessed_no_elmo_vilang\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "> <ipython-input-93-dda015b186d9>(15)test_model()\n",
      "-> return calculate_bleu(translated_predictions, true_labels)\n",
      "(Pdb) translated_predictions[0]\n",
      "'study was much didn . EOS'\n",
      "(Pdb) calculate_bleu(translated_predictions, true_labels)\n",
      "0.2804357270419578\n",
      "(Pdb) true_labels[0]\n",
      "'this is not a finished story .'\n",
      "(Pdb) test_pairs[0]\n",
      "['cau chuyen nay chua ket thuc .', 'this is not a finished story .']\n",
      "(Pdb) translated_predictions[1]\n",
      "'it apos a a . . . EOS'\n",
      "(Pdb) ranslated_predictions[2]\n",
      "*** NameError: name 'ranslated_predictions' is not defined\n",
      "(Pdb) translated_predictions[2]\n",
      "'equipment filmmaker equipment filmmaker backyard maybe aspects of the diet . EOS'\n",
      "(Pdb) true_labels[2]\n",
      "'let me tell you about some of the pieces .'\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-0833173a01fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"greedy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lang\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-93-dda015b186d9>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(encoder, decoder, search, test_pairs, lang1, max_length)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtranslated_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcalculate_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-93-dda015b186d9>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(encoder, decoder, search, test_pairs, lang1, max_length)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtranslated_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcalculate_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/nlpclass/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/nlpclass/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_model(model_e, model_d, \"greedy\", test_pairs, input_lang )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
